{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "%%capture\n",
        "import os, re\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth  # Do this in local & cloud setups\n",
        "else:\n",
        "    import torch; v = re.match(r'[\\d]{1,}\\.[\\d]{1,}', str(torch.__version__)).group(0)\n",
        "    xformers = 'xformers==' + {'2.10':'0.0.34','2.9':'0.0.33.post1','2.8':'0.0.32.post2'}.get(v, \"0.0.34\")\n",
        "    !pip install sentencepiece protobuf \"datasets==4.3.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth_zoo bitsandbytes accelerate {xformers} peft trl triton unsloth\n",
        "!pip install transformers==4.56.2\n",
        "!pip install --no-deps trl==0.22.2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "print(\"hi\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "# One must patch the DPO Trainer first!\n",
        "from unsloth import PatchDPOTrainer\n",
        "\n",
        "PatchDPOTrainer()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 4096 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Llama-3-8B\", # Choose ANY! eg mistralai/Mistral-7B-Instruct-v0.2\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"YOUR_HF_TOKEN\", # HF Token for gated models\n",
        ")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83e\udda5 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "\ud83e\udda5 Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2026.1.4: Fast Llama patching. Transformers: 4.56.2.\n",
            "   \\\\   /|    NVIDIA A100 80GB PCIe. Num GPUs = 1. Max memory: 79.252 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.10.0+cu128. CUDA: 8.0. CUDA Toolkit: 12.8. Triton: 3.6.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.34. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "# @title Alignment Handbook utils\n",
        "import os\n",
        "import re\n",
        "from typing import List, Literal, Optional\n",
        "\n",
        "from datasets import DatasetDict, concatenate_datasets, load_dataset, load_from_disk\n",
        "from datasets.builder import DatasetGenerationError\n",
        "\n",
        "\n",
        "DEFAULT_CHAT_TEMPLATE = \"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\"\n",
        "\n",
        "\n",
        "def apply_chat_template(\n",
        "    example,\n",
        "    tokenizer,\n",
        "    task: Literal[\"sft\", \"generation\", \"rm\", \"dpo\"] = \"sft\",\n",
        "    assistant_prefix = \"<|assistant|>\\n\",\n",
        "):\n",
        "    def _strip_prefix(s, pattern):\n",
        "        # Use re.escape to escape any special characters in the pattern\n",
        "        return re.sub(f\"^{re.escape(pattern)}\", \"\", s)\n",
        "\n",
        "    if task in [\"sft\", \"generation\"]:\n",
        "        messages = example[\"messages\"]\n",
        "        # We add an empty system message if there is none\n",
        "        if messages[0][\"role\"] != \"system\":\n",
        "            messages.insert(0, {\"role\": \"system\", \"content\": \"\"})\n",
        "        example[\"text\"] = tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize = False,\n",
        "            add_generation_prompt = True if task == \"generation\" else False,\n",
        "        )\n",
        "    elif task == \"rm\":\n",
        "        if all(k in example.keys() for k in (\"chosen\", \"rejected\")):\n",
        "            chosen_messages = example[\"chosen\"]\n",
        "            rejected_messages = example[\"rejected\"]\n",
        "            # We add an empty system message if there is none\n",
        "            if chosen_messages[0][\"role\"] != \"system\":\n",
        "                chosen_messages.insert(0, {\"role\": \"system\", \"content\": \"\"})\n",
        "            if rejected_messages[0][\"role\"] != \"system\":\n",
        "                rejected_messages.insert(0, {\"role\": \"system\", \"content\": \"\"})\n",
        "            example[\"text_chosen\"] = tokenizer.apply_chat_template(\n",
        "                chosen_messages, tokenize = False\n",
        "            )\n",
        "            example[\"text_rejected\"] = tokenizer.apply_chat_template(\n",
        "                rejected_messages, tokenize = False\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f\"Could not format example as dialogue for `rm` task! Require `[chosen, rejected]` keys but found {list(example.keys())}\"\n",
        "            )\n",
        "    elif task == \"dpo\":\n",
        "        if all(k in example.keys() for k in (\"chosen\", \"rejected\")):\n",
        "            # Compared to reward modeling, we filter out the prompt, so the text is everything after the last assistant token\n",
        "            prompt_messages = [\n",
        "                [msg for msg in example[\"chosen\"] if msg[\"role\"] == \"user\"][0]\n",
        "            ]\n",
        "            # Insert system message\n",
        "            if example[\"chosen\"][0][\"role\"] != \"system\":\n",
        "                prompt_messages.insert(0, {\"role\": \"system\", \"content\": \"\"})\n",
        "            else:\n",
        "                prompt_messages.insert(0, example[\"chosen\"][0])\n",
        "            # TODO: handle case where chosen/rejected also have system messages\n",
        "            chosen_messages = example[\"chosen\"][1:]\n",
        "            rejected_messages = example[\"rejected\"][1:]\n",
        "            example[\"text_chosen\"] = tokenizer.apply_chat_template(\n",
        "                chosen_messages, tokenize = False\n",
        "            )\n",
        "            example[\"text_rejected\"] = tokenizer.apply_chat_template(\n",
        "                rejected_messages, tokenize = False\n",
        "            )\n",
        "            example[\"text_prompt\"] = tokenizer.apply_chat_template(\n",
        "                prompt_messages, tokenize = False, add_generation_prompt = True\n",
        "            )\n",
        "            example[\"text_chosen\"] = _strip_prefix(\n",
        "                example[\"text_chosen\"], assistant_prefix\n",
        "            )\n",
        "            example[\"text_rejected\"] = _strip_prefix(\n",
        "                example[\"text_rejected\"], assistant_prefix\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f\"Could not format example as dialogue for `dpo` task! Require `[chosen, rejected]` keys but found {list(example.keys())}\"\n",
        "            )\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            f\"Task {task} not supported, please ensure that the provided task is one of {['sft', 'generation', 'rm', 'dpo']}\"\n",
        "        )\n",
        "    return example\n",
        "\n",
        "\n",
        "def get_datasets(\n",
        "    data_config: dict,\n",
        "    splits: List[str] = [\"train\", \"test\"],\n",
        "    shuffle: bool = True,\n",
        ") -> DatasetDict:\n",
        "    \"\"\"\n",
        "    Loads one or more datasets with varying training set proportions.\n",
        "\n",
        "    Args:\n",
        "        data_config (`DataArguments` or `dict`):\n",
        "            Dataset configuration and split proportions.\n",
        "        splits (`List[str]`, *optional*, defaults to `['train', 'test']`):\n",
        "            Dataset splits to load and mix. Assumes the splits exist in all datasets and have a `train_` or `test_` prefix.\n",
        "        shuffle (`bool`, *optional*, defaults to `True`):\n",
        "            Whether to shuffle the training and testing/validation data.\n",
        "\n",
        "    Returns\n",
        "        [`DatasetDict`]: The dataset dictionary containing the loaded datasets.\n",
        "    \"\"\"\n",
        "\n",
        "    if type(data_config) is dict:\n",
        "        # Structure of the input is:\n",
        "        #     dataset_mixer = {\n",
        "        #             \"dataset1\": 0.5,\n",
        "        #             \"dataset1\": 0.3,\n",
        "        #             \"dataset1\": 0.2,\n",
        "        #         }\n",
        "        dataset_mixer = data_config\n",
        "    else:\n",
        "        raise ValueError(f\"Data config {data_config} not recognized.\")\n",
        "\n",
        "    raw_datasets = mix_datasets(dataset_mixer, splits = splits, shuffle = shuffle)\n",
        "    return raw_datasets\n",
        "\n",
        "\n",
        "def mix_datasets(\n",
        "    dataset_mixer: dict, splits: Optional[List[str]] = None, shuffle = True\n",
        ") -> DatasetDict:\n",
        "    \"\"\"\n",
        "    Loads and mixes datasets according to proportions specified in `dataset_mixer`.\n",
        "\n",
        "    Args:\n",
        "        dataset_mixer (`dict`):\n",
        "            Dictionary containing the dataset names and their training proportions. By default, all test proportions are 1.\n",
        "        splits (Optional[List[str]], *optional*, defaults to `None`):\n",
        "            Dataset splits to load and mix. Assumes the splits exist in all datasets and have a `train_` or `test_` prefix.\n",
        "        shuffle (`bool`, *optional*, defaults to `True`):\n",
        "            Whether to shuffle the training and testing/validation data.\n",
        "    \"\"\"\n",
        "    raw_datasets = DatasetDict()\n",
        "    raw_train_datasets = []\n",
        "    raw_val_datasets = []\n",
        "    fracs = []\n",
        "    for ds, frac in dataset_mixer.items():\n",
        "        fracs.append(frac)\n",
        "        for split in splits:\n",
        "            try:\n",
        "                # Try first if dataset on a Hub repo\n",
        "                dataset = load_dataset(ds, split = split)\n",
        "            except DatasetGenerationError:\n",
        "                # If not, check local dataset\n",
        "                dataset = load_from_disk(os.path.join(ds, split))\n",
        "\n",
        "            if \"train\" in split:\n",
        "                raw_train_datasets.append(dataset)\n",
        "            elif \"test\" in split:\n",
        "                raw_val_datasets.append(dataset)\n",
        "            else:\n",
        "                raise ValueError(\n",
        "                    f\"Split type {split} not recognized as one of test or train.\"\n",
        "                )\n",
        "\n",
        "    if any(frac < 0 for frac in fracs):\n",
        "        raise ValueError(\"Dataset fractions cannot be negative.\")\n",
        "\n",
        "    if len(raw_train_datasets) > 0:\n",
        "        train_subsets = []\n",
        "        for dataset, frac in zip(raw_train_datasets, fracs):\n",
        "            train_subset = dataset.select(range(int(frac * len(dataset))))\n",
        "            train_subsets.append(train_subset)\n",
        "        if shuffle:\n",
        "            raw_datasets[\"train\"] = concatenate_datasets(train_subsets).shuffle(seed = 42)\n",
        "        else:\n",
        "            raw_datasets[\"train\"] = concatenate_datasets(train_subsets)\n",
        "    # No subsampling for test datasets to enable fair comparison across models\n",
        "    if len(raw_val_datasets) > 0:\n",
        "        if shuffle:\n",
        "            raw_datasets[\"test\"] = concatenate_datasets(raw_val_datasets).shuffle(\n",
        "                seed = 42\n",
        "            )\n",
        "        else:\n",
        "            raw_datasets[\"test\"] = concatenate_datasets(raw_val_datasets)\n",
        "\n",
        "    if len(raw_datasets) == 0:\n",
        "        raise ValueError(\n",
        "            f\"Dataset {dataset_mixer} not recognized with split {split}. Check the dataset has been correctly formatted.\"\n",
        "        )\n",
        "\n",
        "    return raw_datasets"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "We follow Hugging Face's [Alignment Handbook](https://github.com/huggingface/alignment-handbook) for [Zephyr](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta) and use the [Ultra Feedback dataset](https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized), and sample 0.5% of it to speed things up. You can sample the full dataset for a full run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"SCITLDR.csv\")\n",
        "\n",
        "# Count nulls\n",
        "print(\"Null counts:\")\n",
        "print(df[[\"text\", \"summary\", \"generated_summary\"]].isnull().sum())\n",
        "\n",
        "# Count empty or whitespace-only strings\n",
        "def is_blank(x):\n",
        "    return not isinstance(x, str) or x.strip() == \"\"\n",
        "\n",
        "print(\"\\nBlank (null or empty) counts:\")\n",
        "for col in [\"text\", \"summary\", \"generated_summary\"]:\n",
        "    print(col, df[col].apply(is_blank).sum())\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null counts:\n",
            "text                  0\n",
            "summary               0\n",
            "generated_summary    39\n",
            "dtype: int64\n",
            "\n",
            "Blank (null or empty) counts:\n",
            "text 0\n",
            "summary 0\n",
            "generated_summary 39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "df_clean = df[\n",
        "    df[\"text\"].apply(lambda x: isinstance(x, str) and x.strip() != \"\") &\n",
        "    df[\"summary\"].apply(lambda x: isinstance(x, str) and x.strip() != \"\") &\n",
        "    df[\"generated_summary\"].apply(lambda x: isinstance(x, str) and x.strip() != \"\")\n",
        "].reset_index(drop=True)\n",
        "\n",
        "print(\"Rows before cleaning:\", len(df))\n",
        "print(\"Rows after cleaning:\", len(df_clean))\n",
        "print(\"Dropped rows:\", len(df) - len(df_clean))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows before cleaning: 973\n",
            "Rows after cleaning: 934\n",
            "Dropped rows: 39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "dataset = Dataset.from_pandas(df_clean)\n",
        "\n",
        "dataset = dataset.train_test_split(test_size=0.05, seed=42)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "\n",
        "\n",
        "def prepare_dpo_format(examples):\n",
        "    chosen_messages = []\n",
        "    rejected_messages = []\n",
        "\n",
        "    for text, summary, generated_summary in zip(\n",
        "        examples[\"text\"],\n",
        "        examples[\"summary\"],\n",
        "        examples[\"generated_summary\"]\n",
        "    ):\n",
        "        generated_summary_cleaned = generated_summary.replace(\"[SUMMARY]\", \"\").strip()\n",
        "\n",
        "        user_prompt = (\n",
        "            \"You are an engaging writer.\\n\\n\"\n",
        "            \"A spotlight is a short narrative teaser written as a single paragraph. \"\n",
        "            \"It highlights ONE intriguing angle and sparks curiosity without summarizing.\\n\\n\"\n",
        "            \"Write a spotlight ( 1-2 sentences).\\n\\n\"\n",
        "            f\"### Document:\\n{text}\"\n",
        "        )\n",
        "\n",
        "        chosen_messages.append([\n",
        "            {\"role\": \"user\", \"content\": user_prompt},\n",
        "            {\"role\": \"assistant\", \"content\": summary.strip()},\n",
        "        ])\n",
        "\n",
        "        rejected_messages.append([\n",
        "            {\"role\": \"user\", \"content\": user_prompt},\n",
        "            {\"role\": \"assistant\", \"content\": generated_summary_cleaned},\n",
        "        ])\n",
        "\n",
        "    return {\n",
        "        \"chosen\": chosen_messages,\n",
        "        \"rejected\": rejected_messages,\n",
        "    }\n",
        "\n",
        "\n",
        "# Apply the preparation\n",
        "raw_datasets = dataset.map(\n",
        "    prepare_dpo_format,\n",
        "    batched=True,\n",
        "    num_proc=12,\n",
        "    remove_columns=[\"text\", \"summary\", \"generated_summary\"],\n",
        "    desc=\"Preparing data for DPO format\",\n",
        ")\n",
        "\n",
        "# Set Llama 3 chat template if not already set\n",
        "if tokenizer.chat_template is None:\n",
        "    tokenizer.chat_template = \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\"\n",
        "\n",
        "# Apply chat template\n",
        "column_names = list(raw_datasets[\"train\"].features)\n",
        "raw_datasets = raw_datasets.map(\n",
        "    apply_chat_template,\n",
        "    fn_kwargs={\"tokenizer\": tokenizer, \"task\": \"dpo\"},\n",
        "    num_proc=12,\n",
        "    remove_columns=column_names,\n",
        "    desc=\"Formatting comparisons with prompt template\",\n",
        ")\n",
        "\n",
        "# Rename columns to what TRL expects\n",
        "for split in [\"train\", \"test\"]:\n",
        "    raw_datasets[split] = raw_datasets[split].rename_columns(\n",
        "        {\n",
        "            \"text_prompt\": \"prompt\",\n",
        "            \"text_chosen\": \"chosen\",\n",
        "            \"text_rejected\": \"rejected\",\n",
        "        }\n",
        "    )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d560e1f12aa45cdbb5ec610424f5798",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Preparing data for DPO format (num_proc=12):   0%|          | 0/887 [00:00<?, ? examples/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0551e1e5864440daecb39d1e5a8e569",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Preparing data for DPO format (num_proc=12):   0%|          | 0/47 [00:00<?, ? examples/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "840d0c7a68b3459090e0cb86c38abd1b",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Formatting comparisons with prompt template (num_proc=12):   0%|          | 0/887 [00:00<?, ? examples/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "089b7796bb8d4f2d8dbc1f7c740d84da",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Formatting comparisons with prompt template (num_proc=12):   0%|          | 0/47 [00:00<?, ? examples/s]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We shall print a random item from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "import pprint\n",
        "\n",
        "row = raw_datasets[\"train\"][8]\n",
        "pprint.pprint(row[\"prompt\"])\n",
        "pprint.pprint(row[\"chosen\"])\n",
        "pprint.pprint(row[\"rejected\"])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n'\n",
            " '\\n'\n",
            " '<|eot_id|><|start_header_id|>user<|end_header_id|>\\n'\n",
            " '\\n'\n",
            " 'You are an engaging writer.\\n'\n",
            " '\\n'\n",
            " 'A spotlight is a short narrative teaser written as a single paragraph. It '\n",
            " 'highlights ONE intriguing angle and sparks curiosity without summarizing.\\n'\n",
            " '\\n'\n",
            " 'Write a spotlight ( 1-2 sentences).\\n'\n",
            " '\\n'\n",
            " '### Document:\\n'\n",
            " 'This paper focuses on the synthetic generation of human mobility data in '\n",
            " 'urban areas. We present a novel and scalable application of Generative '\n",
            " 'Adversarial Networks (GANs) for modeling and generating human mobility data. '\n",
            " 'We leverage actual ride requests from ride sharing/hailing services from '\n",
            " 'four major cities in the US to train our GANs model. Our model captures the '\n",
            " 'spatial and temporal variability of the ride-request patterns observed for '\n",
            " 'all four cities on any typical day and over any typical week. Previous works '\n",
            " 'have succinctly characterized the spatial and temporal properties of human '\n",
            " 'mobility data sets using the fractal dimensionality and the densification '\n",
            " 'power law, respectively, which we utilize to validate our GANs-generated '\n",
            " 'synthetic data sets. Such synthetic data sets can avoid privacy concerns and '\n",
            " 'be extremely useful for researchers and policy makers on urban mobility and '\n",
            " 'intelligent transportation. Ride sharing or hailing services have disrupted '\n",
            " 'urban transportation in hundreds of cities around the globe (; BID2 . In '\n",
            " 'United States, it has been estimated that between 24% to 43% of the '\n",
            " 'population have used ride-sharing services in 2018 BID21 . Uber alone '\n",
            " 'operates in more than 600 cities around the globe BID22 . Ride sharing '\n",
            " 'services have turned urban transportation into a convenient utility '\n",
            " '(available any place at any time), and become an important part of the '\n",
            " 'economy in large urban areas BID8.Ride request data from ride sharing '\n",
            " 'services can potentially be of great value. Data gathered from ride sharing '\n",
            " 'services could be used to provide insights about traffic and human mobility '\n",
            " 'patterns which are essential for intelligent transportation systems. Ride '\n",
            " 'requests in major cities with high penetration by such services exhibit '\n",
            " 'spatial and temporal variability. Modeling of such variability is a '\n",
            " 'challenging problem for researchers. Moreover, there are still unresolved '\n",
            " 'challenges, such as: optimal algorithms for dynamic pooling of ride requests '\n",
            " 'BID1, real-time preplacement of vehicles BID12, and city scale traffic '\n",
            " 'congestion prediction BID17 and avoidance. Access to large amount of actual '\n",
            " 'ride request data is essential to understanding and addressing these '\n",
            " 'challenges. Data from ride sharing services have been used for real-time '\n",
            " 'sensing and analytics to yield insights on human mobility patterns BID25 '\n",
            " 'BID11. Each city exhibits a different pattern of urban mobility -there could '\n",
            " 'be cultural or economical factors governing these patterns. If ride sharing '\n",
            " 'services constitute a significant percentage of the riders in a city, can we '\n",
            " 'build models from ride request data to model urban mobility for the whole '\n",
            " 'city and provide societal benefit without compromising personal privacy? '\n",
            " 'This question motivates us to explore the potential of using Generative '\n",
            " 'Adversarial Networks (GANs) to generate synthetic ride request data sets '\n",
            " 'that exhibit very similar attributes as the actual ride request data sets. '\n",
            " 'This work proposes a novel approach of generating synthetic ride request '\n",
            " 'data sets using GANs. This approach involves viewing ride requests as a '\n",
            " '(temporal) sequence of (spatial) images of ride request locations. The '\n",
            " 'approach uses GANs to match the properties of the synthetic data sets with '\n",
            " 'that of real ride request data sets. Many recent works using neural networks '\n",
            " 'have looked at demand prediction BID29 BID30 and traffic prediction at '\n",
            " 'intersections BID28. In our work, we are looking at generating actual ride '\n",
            " 'requests for both spatially and temporally granular intervals. Also, we '\n",
            " 'compare and validate the spatial and temporal variations of the DISPLAYFORM0 '\n",
            " 'Figure 1: Ride requests for a small region of downtown San Francisco for a '\n",
            " 'typical week day. Each figure shows the aggregated ride-locations (red dots) '\n",
            " 'over a period of an hour. Each red dot may represent one or more '\n",
            " 'ride-locations. Ride density varies spatially and temporally.synthetic data '\n",
            " 'sets with the real data sets. In dealing with large amount of data for many '\n",
            " 'cities and long training times for GANs, we develop effective ways to '\n",
            " 'parallelize and scale our GANs training runs using large CPU clusters on '\n",
            " 'AWS. We present our GANs scaling approach and experimental , and show that '\n",
            " 'significant reduction in training times can be achieved. In this section, we '\n",
            " 'introduce the actual (real) ride request data sets used for our GANs '\n",
            " 'training and evaluation. We use the real data sets to compare with and '\n",
            " 'validate the GANs generated synthetic data sets. Our real ride request data '\n",
            " 'sets consist of all the ride requests for an entire week for the four '\n",
            " 'cities. There is a strong repeating pattern from week to week as shown in '\n",
            " 'FIG0. Hence the week-long data should be quite representative. For all four '\n",
            " 'cities, the ride sharing services have significant penetration. Hence we '\n",
            " 'believe the ride request data sets also reflect the overall urban mobility '\n",
            " 'patterns for these cities. Our real data sets are actual ride requests for '\n",
            " 'four cities over one week period from ride sharing services operating in the '\n",
            " 'United States. Each ride request in the data set includes: request time and '\n",
            " 'pickup location (latitude & longitude), and drop-off time and location '\n",
            " '(latitude & longitude). For this work we focus on ride request time and '\n",
            " 'pickup location for generating pickup locations; and ride request time and '\n",
            " 'drop-off location to generate drop-off locations. After training independent '\n",
            " 'GANs models for pickup and drop-off locations, we generate synthetic '\n",
            " 'locations using GANs and leverage graph generator approach BID4 BID11 to '\n",
            " 'pair all pickup and drop-off locations to obtain synthetic ride requests. '\n",
            " 'The trajectory or optimal route for a ride is not within the scope of this '\n",
            " 'work. For the rest of the paper, we will use the term ride-locations to '\n",
            " 'refer to both pickup and drop-off locations wherever they can be used '\n",
            " 'interchangeably. We do temporal and spatial quantization of the raw ride '\n",
            " 'request data from ride sharing services. We partition the entire week into '\n",
            " '2016 time intervals of 5 minutes each, and lump together all the ride '\n",
            " 'requests within each interval. We partition spatially the area of the entire '\n",
            " 'city into small squares with side length,, of 50 meters, and lump together '\n",
            " 'all the ride-locations occurring within the same square area. Each square '\n",
            " 'area is then represented by a single pixel in a 2-D image with the gray '\n",
            " 'scale intensity of the pixel reflecting the number of ride-locations in that '\n",
            " 'square area (in a time interval). Occurrence of no ride-locations in an area '\n",
            " 'is denoted by zero pixel intensity; positive integers (1, 2, 3, . . .) as '\n",
            " 'pixel intensity denote the number of ride-locations in the square area. '\n",
            " 'Combining the temporal and spatial quantizations, the real ride request data '\n",
            " 'set for each city becomes a time sequence of images with each image '\n",
            " 'spatially capturing all the ride requests occurring in a particular 5-min '\n",
            " 'interval. The actual ride requests in every city exhibit distinct patterns '\n",
            " 'of variability in both the spatial dimension (over geographical area of the '\n",
            " 'city) and the temporal dimension (over each day and over each week). In '\n",
            " 'Figure 1, this variability is illustrated. The ride request density is at '\n",
            " 'its highest at 6pm, and continually decreases over time till 3am. Spatially '\n",
            " 'there are dense patches of ride requests and these dense patches can shift '\n",
            " 'with time, reflecting shifting concentrations of commuters in different '\n",
            " 'areas at different times of day. We observe similar repeating patterns of '\n",
            " 'temporal and spatial variability for all four cities. Previous works have '\n",
            " 'been able to characterize these temporal and spatial variability patterns '\n",
            " 'BID11. A graph can be used to model the ride requests within a 5-min '\n",
            " 'interval, with nodes 1 representing pickup and drop off locations and a '\n",
            " 'directed edge connecting the pickup node and the drop-off node. It was shown '\n",
            " 'in BID11 ) that the size and density of this Ride Request Graph (RRG) '\n",
            " 'evolves in time in response to the fluctuation of ride requests during each '\n",
            " 'day and through out each week. It was observed that these ride request '\n",
            " 'graphs exhibit and obey the Densification Power Law (DPL) property, similar '\n",
            " 'to other graphs modeling human behaviors such as social networking graphs '\n",
            " 'and publication citation graphs BID16. It was further observed that the ride '\n",
            " 'request graphs for each city exhibit a distinct degree or exponent of the '\n",
            " 'DPL, and that this DPL Exponent (\u03b1) can be viewed as a very succinct '\n",
            " 'quantitative characterization of the temporal variability of the ride '\n",
            " 'request patterns for that city. For any time snapshot t: DISPLAYFORM0 where '\n",
            " 'e(t) and n(t) are the number of edges and number of nodes respectively, '\n",
            " 'formed by all ride requests occurring in the time interval t. Edge weight '\n",
            " 'denote the number of requests from the same source (pickup) to destination '\n",
            " '(drop-off) nodes in time snapshot t. The number of edges grows according to '\n",
            " 'a specific exponential power (\u03b1) of the number of nodes. There is also a '\n",
            " 'comparable quantitative characterization of the spatial variability of the '\n",
            " 'ride request patterns for each city. The actual geographical locations of '\n",
            " 'the nodes of the ride request graphs is not explicitly represented and '\n",
            " 'therefore another characterization is needed. Correlation Fractal Dimension '\n",
            " 'BID24 BID0 ) provides a succinct description of a kdimensional point-set to '\n",
            " 'provide statistics about the distribution of points; it provides a '\n",
            " 'quantitative measure of self-similarity. The spatial distribution of ride '\n",
            " 'requests in each time interval can be viewed as a point-set image. We can '\n",
            " 'measure the Correlation Fractal Dimension (D 2) as described in BID12. '\n",
            " 'Values for correlation fractal dimension computed for each time snapshot t '\n",
            " 'fall within a range for each city indicating the degree of self-similarity, '\n",
            " 'and the consistent weekly pattern. For our 2-dimenional space, we impose a '\n",
            " '2D-grid with square of side 2. For the i-th square, let C,i be the count of '\n",
            " 'requests in each square. The correlation fractal dimension is defined as: '\n",
            " 'DISPLAYFORM1 For self-similar data sets, we expect the derivative to be '\n",
            " 'constant for a certain range of BID27. We observe that this range varies for '\n",
            " 'our four cities, and each city exhibits a distinct value range for its '\n",
            " 'correlation fractal dimension (D 2).We use the Densification Power Law '\n",
            " 'Exponent (\u03b1) and the Correlation Fractal Dimension (D 2) to capture and '\n",
            " 'characterize the temporal and spatial variability, respectively, for the '\n",
            " 'ride request patterns for each city. RRG created for every time snapshot '\n",
            " 'captures ridership fluctuations over time; nodes in a RRG do not encode any '\n",
            " 'spatial information. Therefore, we compute Correlation Fractal Dimension for '\n",
            " 'each time snapshot to capture the spatial distribution of both pickup and '\n",
            " 'dropoff locations. The temporal evolution, and spatial distribution at any '\n",
            " 'give time snapshot capture the dynamics of ride requests. We use these two '\n",
            " 'parameters independently to confirm the similarity between the real data '\n",
            " 'sets and the GANs generated synthetic data sets. We can claim strong '\n",
            " 'similarity if the values of these two parameters (\u03b1 and D 2) of the '\n",
            " 'synthetic data sets match closely the values of the same two parameters of '\n",
            " 'the real data sets. Generative Adversarial Networks learn to generate high '\n",
            " 'quality samples i.e. sample from the data distribution p(x). Previous works '\n",
            " 'by BID3 BID14 ) synthesized images of a higher quality using GANs which were '\n",
            " 'hard for humans to distinguish from real images. Conditional GANs are an '\n",
            " 'extension of GANs to sample from a conditional distribution given each image '\n",
            " 'has an associated label which is true for our case of ride requests. In our '\n",
            " 'framework, we would apply conditional GANs using ride request data in the '\n",
            " 'form of images; similar to as shown in Figure 1 but without the base map '\n",
            " 'shown in color. GANs learn a mapping from a random noise vector z to output '\n",
            " 'image x. Conditional GANs learn a mapping from noise vector z and a label y '\n",
            " 'to x BID18 BID5. The additional variable in the model allows to generate and '\n",
            " 'discriminate samples conditioned on y. The generator accepts noise data z '\n",
            " 'along with y to produce an image. The discriminator accepts an image x and '\n",
            " 'condition y to predict the probability under condition y that x came from '\n",
            " 'the empirical data distribution rather than from the generative model. The '\n",
            " 'objective function can be expressed as: DISPLAYFORM0 where G tries to '\n",
            " 'minimize to this objective function against an adversarial D that tries to '\n",
            " 'maximize it. Every image is assigned a label from the set {0, 1, 2, ..., 23} '\n",
            " 'representing the hour of a day. All twelve instances of five minute '\n",
            " 'snapshots within an hour are assigned the same hour label 3. To accelerate '\n",
            " 'our training using multiple machines, we exploit spatial parallelism by '\n",
            " 'dividing the entire geographical region of a city into an array of blocks. '\n",
            " 'FIG1 illustrates the division of San Francisco downtown into nine blocks. '\n",
            " 'Keeping our image size similar to MNIST BID23, each block is set to '\n",
            " 'represent an image of size 24\u00d724 pixels, with each pixel representing one '\n",
            " '50m\u00d750m square area. Hence, each block covers an area of 1200m \u00d7 1200m. Each '\n",
            " 'block, representing a grey scale image of 24 \u00d7 24 pixels, depicts all the '\n",
            " 'ride-locations in that block. Separate images are formed for pickup and '\n",
            " 'drop-off locations; models trained are also separate for pickup and drop-off '\n",
            " 'locations. Each image of a block is labeled with a time interval (for our '\n",
            " 'experiments, the hour in a day) which is similar for both images created '\n",
            " 'from pickup and drop-off locations. The synthetically generated images from '\n",
            " 'an array of blocks with the same time interval label are combined by '\n",
            " 'stitching together all the processed blocks of a city. The generator network '\n",
            " 'takes an input of a 100-dimensional Gaussian noise sample as well as a '\n",
            " 'onehot vector encoding of the time snapshot to be generated. It has a '\n",
            " 'single, fully-connected hidden layer without any convolution BID6 consisting '\n",
            " 'of 128 ReLU-activated neurons which then passes to a sigmoid activated '\n",
            " 'output layer with the same number of output neurons as the total number of '\n",
            " 'pixels in each block. The discriminator network has a single hidden layer of '\n",
            " '128 ReLU-activated neurons with a single sigmoid activated output neuron. We '\n",
            " 'find that small networks are appropriate for the training data and allow for '\n",
            " 'a quick and stable convergence to be achieved between the discriminator and '\n",
            " 'the generator. Using relatively simple network architectures makes it '\n",
            " 'possible to ensure that the discriminator and generator are evenly matched '\n",
            " 'such that the loss for either network does not saturate early in the '\n",
            " 'training process. In addition to the standard GANs architecture of generator '\n",
            " 'and discriminator, an additional network is introduced which is referred to '\n",
            " 'as the classifier BID15; it is pre-trained on the training data with the '\n",
            " 'five minute label of the data serving as the classification target. In this '\n",
            " 'way the time information that is encoded into the synthetic data by the '\n",
            " 'generator network is then decoded by the classifier network. The generator '\n",
            " 'is then trained on a weighted sum of the loss from both the classifier and '\n",
            " 'discriminator networks as shown in the following equation: DISPLAYFORM0 '\n",
            " 'where \u03b2 is a tune-able hyper-parameter. This allows for more explicit loss '\n",
            " 'attribution such that the generator receives two different error signals; '\n",
            " 'one indicating the realism of the synthetic data and the other indicating '\n",
            " 'accuracy relative to the conditioning values. By experiments using MNIST '\n",
            " 'data and BID15, we found adding a classifier increases the efficiency of the '\n",
            " 'training process and in higher quality synthetic data while incurring '\n",
            " 'considerably less training time than other conditional GANs architectures we '\n",
            " 'have experimented. In this section, we present the cloud infrastructure used '\n",
            " 'for running our experiments. We also present performance on scaling our GANs '\n",
            " 'workloads on the cloud infrastructure. All experiments are conducted on '\n",
            " 'Amazon Web Services (AWS) using c5.18x instances with each instance '\n",
            " 'containing an Intel Xeon Scalable Processor with 72 virtual cores (vCores) '\n",
            " 'running at 3.0GHz and 144 GB of RAM. In this work we set the block size for '\n",
            " 'each of the four cities to be 1200 \u00d7 1200 meters; each block is trained '\n",
            " 'separately. Enlarging the block size will increase the computational time '\n",
            " 'for training; and the complexity of the model can potentially impact '\n",
            " 'scalability. The total number of blocks for each city are shown in TAB0. The '\n",
            " 'number of blocks are mainly determined by the size of the greater '\n",
            " 'metropolitan area of each city. To help enhance the scalability of our GANs '\n",
            " 'workload across multiple nodes we make use of Ray BID19 from Berkeley, a '\n",
            " 'distributed framework for AI Applications, to efficiently parallelize our '\n",
            " 'workload across cluster of CPU nodes on AWS. Ray provides a convenient API '\n",
            " 'in Python to scale deep learning workloads for numerous libraries, and '\n",
            " 'support for heterogeneous resources like CPUs and GPUs. We also make use of '\n",
            " \"Intel's Math Kernel Library Intel (2018b) (MKL) which provides machine \"\n",
            " 'learning libraries for supporting operations like activation (ReLU), inner '\n",
            " 'product, and other useful functions BID9. Using Ray we scale our training '\n",
            " 'runs by using from 2 to 8 c5.18x instances (containing from 144 cores to 576 '\n",
            " 'cores) on AWS. The scalability are shown in Figure 4. As can be seen '\n",
            " 'increasing the number of c5.18X Xeon CPU instances can significantly reduce '\n",
            " 'the GANs training time up to 8 c5.18x instances. For the city of Los '\n",
            " 'Angeles, the training time can be reduced from over one hour to less than 20 '\n",
            " 'minutes. For New York City the training time can be reduced to just minutes. '\n",
            " 'Running times for sampling ride requests from the trained models and '\n",
            " 'stitching the images of all the blocks together are significantly less than '\n",
            " 'the training times, and are not included in these . We also conduct our GANs '\n",
            " 'scaling experiments using GPU instances on AWS. In our initial experiments '\n",
            " 'we observe no real performance improvements using GPUs. Training time using '\n",
            " 'GPUs on AWS was observed to be 5.93 hours on a p3.8xlarge instance using '\n",
            " \"NVIDIA's Multi-Process Service (MPS) . With MPS, the GPU utilization is \"\n",
            " 'close to maximum by running multiple of our small GANs training jobs in '\n",
            " 'parallel on a single GPU. Although, the number of jobs which could be '\n",
            " 'executed in parallel on a GPU are not that many in comparison to Xeons. '\n",
            " 'Scaling on GPUs requires more investigation. In this work, we show that it '\n",
            " 'is possible to achieve very nice scalability of our GANs workload using only '\n",
            " \"CPU cores supported by Intel's MKL library and Berkeley's Ray framework. The \"\n",
            " 'correlation fractal dimension (D 2) gives a bound on the number of ride '\n",
            " 'requests within a geographical region. This is an essential characteristic '\n",
            " 'to match for the data set we are generating using GANs. In TAB3, we provide '\n",
            " 'the fractal range for each city within which the fractal dimension remains '\n",
            " 'constant. It is important to note that the fractal range for each city '\n",
            " 'differs. The fractal range provides the range for which the data exhibits '\n",
            " 'statistical self-similarity BID0. The variation in the fractal ranges for '\n",
            " 'the different cities can be attributed to the geographical shape of the city '\n",
            " 'for which the ride requests are generated. We hypothesize that due to Los '\n",
            " \"Angeles's sprawling nature, a larger is needed to observe self-similar \"\n",
            " 'patterns in comparison to the other three cities, which have a more '\n",
            " 'corridor-like geographical region. Table 2: Summary of measured correlation '\n",
            " 'fractal dimensions (D 2) for four cities; computed over a day for every hour '\n",
            " 'using pickup locations of real and synthetic data sets. One may also '\n",
            " 'interpret D 2 as a way to measure the fidelity of generated images to that '\n",
            " 'from real data. Comparison of the ranges of values of D 2, in terms of min, '\n",
            " 'max, and mean values, for the real and the synthetic data sets are fairly '\n",
            " 'close although not identical. In most instances the mean value for D 2 is '\n",
            " 'lower for the synthetic data sets in comparison to the real data sets. We '\n",
            " 'believe this discrepancy in the values of D 2 require further investigation. '\n",
            " 'Recent works to improve capture learning of highresolution details of an '\n",
            " 'image BID13 can potentially benefit the learning for our ride request '\n",
            " 'images. DPL provides a characterization of the temporal evolution of ride '\n",
            " 'requests. In the top row of Figure 5 we observe the plot of the DPL '\n",
            " 'exponents \u03b1 (slop of the line) based on the temporal patterns of the real '\n",
            " 'data sets. For the ride request graph to obey DPL properties, we use graph '\n",
            " 'generator proposed by BID11 to connect source and destination locations. In '\n",
            " 'the bottom row of Figure 5 we see the same based on the synthetic data sets. '\n",
            " 'We can see that the DPL exponent values \u03b1 correlated quite nicely with that '\n",
            " 'from the real data sets for New York, Chicago, and San Francisco. Figure 5: '\n",
            " 'DPL plots from real data (top row) and synthetic data (bottom row) for four '\n",
            " 'cities. The red line is the least square fit of the form y = Cx \u03b1, where y '\n",
            " 'and x are number of edges and nodes respectively. R 2 \u2248 1.00 for all of '\n",
            " 'them. For Los Angeles, the synthetic exponent is higher than the real '\n",
            " 'observed value; the geographical region for LA is much larger and due to '\n",
            " 'many prominent regions of high request density, the model may likely suffer '\n",
            " 'from bias towards generating more requests in prominent regions leading to a '\n",
            " 'faster increase of the number of edges connecting nodes present in high '\n",
            " 'density regions. Another validation of our GANs approach is provided in '\n",
            " 'Figure 6. Here we observe temporal variation of ride requests in terms of '\n",
            " 'the volume of ride requests generated for each hour of a typical weekday. We '\n",
            " 'see that for all four cities, the temporal variation of the synthetic data '\n",
            " 'sets match quite well the temporal variation exhibited by the actual data '\n",
            " 'set. The emergence of ride sharing services and the availability of '\n",
            " 'extensive data sets from such services are creating unprecedented '\n",
            " 'opportunities for: 1) doing city-scale data analytics on urban '\n",
            " 'transportation for supporting Intelligent Transportation Systems (ITS); 2) '\n",
            " 'improving the efficiency of ride sharing services; 3) facilitating real-time '\n",
            " 'traffic congestion prediction; and 4) providing new public services for '\n",
            " 'societal benefit. Moreover, the power of neural networks for machine '\n",
            " 'learning has allowed the creation of useful models which can capture human '\n",
            " 'behavior and dynamic real-world scenarios. The key contributions of this '\n",
            " 'paper include:\u2022 We map the ride requests of ride sharing services into a '\n",
            " 'time sequence of images that capture both the temporal and spatial '\n",
            " 'attributes of ride request patterns for a city.\u2022 Based on extensive real '\n",
            " 'world ride request data, we introduce a GANs based workflow for modeling and '\n",
            " 'generating synthetic and realistic ride request data sets for a city.\u2022 We '\n",
            " 'further show that our GANs workload can be effectively scaled using Xeon CPU '\n",
            " 'clusters on AWS, in reducing training times from hours to minutes for each '\n",
            " 'city.\u2022 Using previous work on modelling urban mobility patterns, we validate '\n",
            " 'our GANs generated data sets for ride requests for four major US cities, by '\n",
            " 'comparing the spatial and temporal properties of the GANs generated data '\n",
            " 'sets against that of the real data sets. There are other promising avenues '\n",
            " 'for further research. Some open research topics include: Figure 6: Plots for '\n",
            " 'four cities highlighting the temporal variability of ride requests visible '\n",
            " 'in both real and our model (predicted) for ride request generation. The '\n",
            " 'pattern is representative of any typical day of week.\u2022 Using the GANs '\n",
            " 'generated data sets for experiments on new algorithms for dynamic ride '\n",
            " 'pooling, real-time pre-placement of vehicles, and real-time traffic '\n",
            " 'congestion prediction. \u2022 Using the GANs generated data sets for conducting '\n",
            " 'experiments on what-if scenarios related to traffic congestion prediction '\n",
            " 'and mitigation, and planning for future development of transportation '\n",
            " 'infrastructures. We are currently pursuing these research topics. As our '\n",
            " 'GANs generated data sets are used in our follow up research, we plan to '\n",
            " 'further validate the synthetic data sets by comparing our research with from '\n",
            " 'using the real data sets. We plan to continue to tune our GANs models and '\n",
            " 'generate improved synthetic data sets that can be made available for other '\n",
            " 'researchers.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n'\n",
            " '\\n')\n",
            "('<|begin_of_text|><|start_header_id|>assistant<|end_header_id|>\\n'\n",
            " '\\n'\n",
            " 'This paper focuses on the synthetic generation of human mobility data in '\n",
            " 'urban areas using GANs.<|eot_id|>')\n",
            "('<|begin_of_text|><|start_header_id|>assistant<|end_header_id|>\\n'\n",
            " '\\n'\n",
            " 'We present a novel and scalable application of Generative Adversarial '\n",
            " 'Networks (GANs) for modeling and generating human mobility data in urban '\n",
            " 'areas.<|eot_id|>')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 32,\n",
        "    lora_dropout = 0, # Currently only supports dropout = 0\n",
        "    bias = \"none\",    # Currently only supports bias = \"none\"\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2026.1.4 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the DPO model\n",
        "Now let's train our model. We do 3 epochs on 0.5% of the dataset to speed things up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "# One must patch the DPO Trainer first!\n",
        "from unsloth import PatchDPOTrainer\n",
        "\n",
        "PatchDPOTrainer()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "from transformers import TrainingArguments\n",
        "from trl import DPOTrainer, DPOConfig\n",
        "dpo_trainer = DPOTrainer(\n",
        "    model = model,\n",
        "    ref_model = None,\n",
        "    args = DPOConfig(\n",
        "        per_device_train_batch_size = 4,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_ratio = 0.1,\n",
        "        num_train_epochs = 2,\n",
        "        learning_rate = 5e-6,\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.0,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 42,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\", # Use TrackIO/WandB etc\n",
        "    ),\n",
        "    beta = 0.1,\n",
        "    train_dataset = raw_datasets[\"train\"],\n",
        "    # eval_dataset = raw_datasets[\"test\"],\n",
        "    tokenizer = tokenizer,\n",
        "    max_length = 1024,\n",
        "    max_prompt_length = 512,\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f93fa38bf1ed4370aaa6a7ae4ff80be8",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Extracting prompt in train dataset (num_proc=47):   0%|          | 0/887 [00:00<?, ? examples/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9722d5ba19e74a3c9f36f52b49b9b274",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Applying chat template to train dataset (num_proc=47):   0%|          | 0/887 [00:00<?, ? examples/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "530c1972a54b452da5c6ebe6ea5754b4",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Tokenizing train dataset (num_proc=47):   0%|          | 0/887 [00:00<?, ? examples/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[accelerate.utils.other|WARNING]Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "dpo_trainer.train()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 887 | Num Epochs = 2 | Total steps = 112\n",
            "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n",
            " \"-____-\"     Trainable parameters = 41,943,040 of 8,072,204,288 (0.52% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='112' max='112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [112/112 16:15, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>rewards / chosen</th>\n      <th>rewards / rejected</th>\n      <th>rewards / accuracies</th>\n      <th>rewards / margins</th>\n      <th>logps / chosen</th>\n      <th>logps / rejected</th>\n      <th>logits / chosen</th>\n      <th>logits / rejected</th>\n      <th>eval_logits / chosen</th>\n      <th>eval_logits / rejected</th>\n      <th>nll_loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.693100</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-159.232971</td>\n      <td>-364.198975</td>\n      <td>-1.270524</td>\n      <td>-1.297501</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.693100</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-138.449753</td>\n      <td>-379.281158</td>\n      <td>-1.308092</td>\n      <td>-1.277941</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.691500</td>\n      <td>0.005856</td>\n      <td>0.002223</td>\n      <td>0.687500</td>\n      <td>0.003633</td>\n      <td>-145.173264</td>\n      <td>-288.661377</td>\n      <td>-1.291631</td>\n      <td>-1.247630</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.696300</td>\n      <td>-0.004272</td>\n      <td>0.001386</td>\n      <td>0.375000</td>\n      <td>-0.005658</td>\n      <td>-154.167648</td>\n      <td>-450.785645</td>\n      <td>-1.361730</td>\n      <td>-1.288816</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.678500</td>\n      <td>0.009127</td>\n      <td>-0.021080</td>\n      <td>0.687500</td>\n      <td>0.030207</td>\n      <td>-150.537140</td>\n      <td>-290.371887</td>\n      <td>-1.312384</td>\n      <td>-1.057185</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.686300</td>\n      <td>0.013015</td>\n      <td>-0.000916</td>\n      <td>0.562500</td>\n      <td>0.013931</td>\n      <td>-143.910324</td>\n      <td>-324.714294</td>\n      <td>-1.226626</td>\n      <td>-1.228027</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.696300</td>\n      <td>0.005242</td>\n      <td>0.010958</td>\n      <td>0.562500</td>\n      <td>-0.005716</td>\n      <td>-147.543640</td>\n      <td>-327.657501</td>\n      <td>-1.325947</td>\n      <td>-1.265301</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.696200</td>\n      <td>-0.001120</td>\n      <td>0.004620</td>\n      <td>0.375000</td>\n      <td>-0.005740</td>\n      <td>-158.785034</td>\n      <td>-318.522552</td>\n      <td>-1.318402</td>\n      <td>-1.227860</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.693800</td>\n      <td>-0.008678</td>\n      <td>-0.008133</td>\n      <td>0.375000</td>\n      <td>-0.000546</td>\n      <td>-155.159943</td>\n      <td>-414.361328</td>\n      <td>-1.346766</td>\n      <td>-1.340060</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.690900</td>\n      <td>-0.001413</td>\n      <td>-0.006243</td>\n      <td>0.437500</td>\n      <td>0.004830</td>\n      <td>-146.806824</td>\n      <td>-361.603943</td>\n      <td>-1.289413</td>\n      <td>-1.263180</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.679600</td>\n      <td>0.009636</td>\n      <td>-0.018203</td>\n      <td>0.687500</td>\n      <td>0.027839</td>\n      <td>-151.117920</td>\n      <td>-318.718262</td>\n      <td>-1.260438</td>\n      <td>-1.049374</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.685700</td>\n      <td>0.005563</td>\n      <td>-0.009697</td>\n      <td>0.687500</td>\n      <td>0.015261</td>\n      <td>-144.492371</td>\n      <td>-341.854492</td>\n      <td>-1.218816</td>\n      <td>-1.183200</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.676900</td>\n      <td>0.021764</td>\n      <td>-0.011798</td>\n      <td>0.687500</td>\n      <td>0.033562</td>\n      <td>-159.555847</td>\n      <td>-457.449463</td>\n      <td>-1.431799</td>\n      <td>-1.306419</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.680000</td>\n      <td>0.003097</td>\n      <td>-0.023910</td>\n      <td>0.750000</td>\n      <td>0.027007</td>\n      <td>-145.200165</td>\n      <td>-337.038574</td>\n      <td>-1.317807</td>\n      <td>-1.229035</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.663500</td>\n      <td>0.052075</td>\n      <td>-0.009248</td>\n      <td>0.812500</td>\n      <td>0.061323</td>\n      <td>-154.357819</td>\n      <td>-343.596375</td>\n      <td>-1.259184</td>\n      <td>-1.165871</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.686800</td>\n      <td>0.023643</td>\n      <td>0.010542</td>\n      <td>0.750000</td>\n      <td>0.013101</td>\n      <td>-145.255035</td>\n      <td>-224.672256</td>\n      <td>-1.315703</td>\n      <td>-1.277436</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.676000</td>\n      <td>0.017322</td>\n      <td>-0.018917</td>\n      <td>0.562500</td>\n      <td>0.036239</td>\n      <td>-158.708725</td>\n      <td>-354.597748</td>\n      <td>-1.365241</td>\n      <td>-1.139611</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.672600</td>\n      <td>0.031831</td>\n      <td>-0.010982</td>\n      <td>0.625000</td>\n      <td>0.042813</td>\n      <td>-144.549713</td>\n      <td>-280.318909</td>\n      <td>-1.413468</td>\n      <td>-1.298264</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.675500</td>\n      <td>0.035993</td>\n      <td>-0.000859</td>\n      <td>0.625000</td>\n      <td>0.036853</td>\n      <td>-143.214752</td>\n      <td>-266.659210</td>\n      <td>-1.299051</td>\n      <td>-1.158515</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.677300</td>\n      <td>0.023532</td>\n      <td>-0.009025</td>\n      <td>0.687500</td>\n      <td>0.032557</td>\n      <td>-142.020142</td>\n      <td>-317.060059</td>\n      <td>-1.208746</td>\n      <td>-1.413141</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.679500</td>\n      <td>0.032749</td>\n      <td>0.004327</td>\n      <td>0.625000</td>\n      <td>0.028422</td>\n      <td>-144.324402</td>\n      <td>-234.460724</td>\n      <td>-1.248587</td>\n      <td>-0.985487</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.650900</td>\n      <td>0.060600</td>\n      <td>-0.027397</td>\n      <td>0.875000</td>\n      <td>0.087997</td>\n      <td>-156.013824</td>\n      <td>-394.368347</td>\n      <td>-1.402000</td>\n      <td>-1.306931</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.646000</td>\n      <td>0.069788</td>\n      <td>-0.028504</td>\n      <td>0.875000</td>\n      <td>0.098292</td>\n      <td>-140.104828</td>\n      <td>-345.425171</td>\n      <td>-1.308876</td>\n      <td>-1.160991</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.634900</td>\n      <td>0.063084</td>\n      <td>-0.059772</td>\n      <td>0.875000</td>\n      <td>0.122857</td>\n      <td>-141.242035</td>\n      <td>-340.672241</td>\n      <td>-1.318295</td>\n      <td>-1.220042</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.636400</td>\n      <td>0.007549</td>\n      <td>-0.113599</td>\n      <td>0.750000</td>\n      <td>0.121148</td>\n      <td>-147.995361</td>\n      <td>-379.054688</td>\n      <td>-1.274300</td>\n      <td>-1.407866</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>0.619500</td>\n      <td>0.057981</td>\n      <td>-0.099171</td>\n      <td>0.937500</td>\n      <td>0.157152</td>\n      <td>-152.385086</td>\n      <td>-367.078552</td>\n      <td>-1.391994</td>\n      <td>-1.269935</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>0.647900</td>\n      <td>0.066684</td>\n      <td>-0.030366</td>\n      <td>0.750000</td>\n      <td>0.097050</td>\n      <td>-160.796844</td>\n      <td>-278.322693</td>\n      <td>-1.376406</td>\n      <td>-1.088135</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.640200</td>\n      <td>0.103537</td>\n      <td>-0.010658</td>\n      <td>0.812500</td>\n      <td>0.114194</td>\n      <td>-140.656921</td>\n      <td>-228.509216</td>\n      <td>-1.294971</td>\n      <td>-1.043406</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>0.629200</td>\n      <td>0.098560</td>\n      <td>-0.038452</td>\n      <td>0.812500</td>\n      <td>0.137011</td>\n      <td>-143.637848</td>\n      <td>-287.820160</td>\n      <td>-1.301292</td>\n      <td>-1.135176</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.596400</td>\n      <td>0.080598</td>\n      <td>-0.130441</td>\n      <td>0.937500</td>\n      <td>0.211038</td>\n      <td>-151.129913</td>\n      <td>-369.732361</td>\n      <td>-1.401808</td>\n      <td>-1.314619</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>0.623800</td>\n      <td>0.064474</td>\n      <td>-0.088388</td>\n      <td>0.750000</td>\n      <td>0.152863</td>\n      <td>-134.659195</td>\n      <td>-315.407837</td>\n      <td>-1.313355</td>\n      <td>-1.208392</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>0.554200</td>\n      <td>0.179168</td>\n      <td>-0.132507</td>\n      <td>0.875000</td>\n      <td>0.311675</td>\n      <td>-150.804779</td>\n      <td>-360.328735</td>\n      <td>-1.357164</td>\n      <td>-1.103671</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>0.605300</td>\n      <td>0.115775</td>\n      <td>-0.079592</td>\n      <td>0.812500</td>\n      <td>0.195367</td>\n      <td>-148.029739</td>\n      <td>-319.081177</td>\n      <td>-1.302422</td>\n      <td>-1.211003</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>0.582300</td>\n      <td>0.103516</td>\n      <td>-0.149626</td>\n      <td>0.750000</td>\n      <td>0.253142</td>\n      <td>-153.976990</td>\n      <td>-316.949219</td>\n      <td>-1.332582</td>\n      <td>-1.202114</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.592300</td>\n      <td>0.145043</td>\n      <td>-0.084777</td>\n      <td>0.750000</td>\n      <td>0.229820</td>\n      <td>-143.657364</td>\n      <td>-292.224976</td>\n      <td>-1.267368</td>\n      <td>-0.935286</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>0.588900</td>\n      <td>0.133303</td>\n      <td>-0.110841</td>\n      <td>0.812500</td>\n      <td>0.244144</td>\n      <td>-145.022308</td>\n      <td>-257.234650</td>\n      <td>-1.200106</td>\n      <td>-1.176866</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>0.525600</td>\n      <td>0.186797</td>\n      <td>-0.223438</td>\n      <td>0.812500</td>\n      <td>0.410235</td>\n      <td>-146.096909</td>\n      <td>-357.081238</td>\n      <td>-1.313420</td>\n      <td>-1.232062</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>0.533400</td>\n      <td>0.192522</td>\n      <td>-0.197725</td>\n      <td>0.812500</td>\n      <td>0.390247</td>\n      <td>-151.937012</td>\n      <td>-346.674591</td>\n      <td>-1.293819</td>\n      <td>-1.164330</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>0.552000</td>\n      <td>0.146560</td>\n      <td>-0.187240</td>\n      <td>0.750000</td>\n      <td>0.333800</td>\n      <td>-158.945419</td>\n      <td>-342.072296</td>\n      <td>-1.311562</td>\n      <td>-1.261111</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.482000</td>\n      <td>0.211698</td>\n      <td>-0.315819</td>\n      <td>0.875000</td>\n      <td>0.527517</td>\n      <td>-148.334229</td>\n      <td>-375.817444</td>\n      <td>-1.258691</td>\n      <td>-1.153424</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>0.463700</td>\n      <td>0.151831</td>\n      <td>-0.426079</td>\n      <td>0.875000</td>\n      <td>0.577910</td>\n      <td>-138.800797</td>\n      <td>-447.005981</td>\n      <td>-1.257190</td>\n      <td>-1.231137</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>0.465700</td>\n      <td>0.195914</td>\n      <td>-0.374771</td>\n      <td>1.000000</td>\n      <td>0.570685</td>\n      <td>-149.637573</td>\n      <td>-393.732178</td>\n      <td>-1.272085</td>\n      <td>-1.424950</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>0.501000</td>\n      <td>0.198514</td>\n      <td>-0.284132</td>\n      <td>0.937500</td>\n      <td>0.482647</td>\n      <td>-146.332642</td>\n      <td>-352.573944</td>\n      <td>-1.251766</td>\n      <td>-1.280243</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>0.451900</td>\n      <td>0.196440</td>\n      <td>-0.447926</td>\n      <td>0.875000</td>\n      <td>0.644366</td>\n      <td>-161.273911</td>\n      <td>-431.104309</td>\n      <td>-1.288705</td>\n      <td>-1.340446</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.444300</td>\n      <td>0.254540</td>\n      <td>-0.385921</td>\n      <td>0.937500</td>\n      <td>0.640461</td>\n      <td>-155.608109</td>\n      <td>-395.727112</td>\n      <td>-1.308491</td>\n      <td>-1.222811</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>0.442200</td>\n      <td>0.192928</td>\n      <td>-0.488727</td>\n      <td>0.875000</td>\n      <td>0.681655</td>\n      <td>-157.355850</td>\n      <td>-358.480774</td>\n      <td>-1.237428</td>\n      <td>-1.166598</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>0.428500</td>\n      <td>0.221144</td>\n      <td>-0.514940</td>\n      <td>0.875000</td>\n      <td>0.736084</td>\n      <td>-144.106903</td>\n      <td>-388.126953</td>\n      <td>-1.294495</td>\n      <td>-1.185232</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>0.462600</td>\n      <td>0.185790</td>\n      <td>-0.481629</td>\n      <td>0.937500</td>\n      <td>0.667419</td>\n      <td>-146.893677</td>\n      <td>-337.872009</td>\n      <td>-1.290302</td>\n      <td>-1.135383</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>0.445600</td>\n      <td>0.290063</td>\n      <td>-0.441033</td>\n      <td>0.812500</td>\n      <td>0.731097</td>\n      <td>-148.414886</td>\n      <td>-356.125549</td>\n      <td>-1.354225</td>\n      <td>-1.227599</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.437100</td>\n      <td>0.255268</td>\n      <td>-0.478059</td>\n      <td>0.875000</td>\n      <td>0.733327</td>\n      <td>-141.523071</td>\n      <td>-343.248108</td>\n      <td>-1.255037</td>\n      <td>-1.214716</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>0.432200</td>\n      <td>0.341243</td>\n      <td>-0.408216</td>\n      <td>0.812500</td>\n      <td>0.749459</td>\n      <td>-152.015411</td>\n      <td>-353.073853</td>\n      <td>-1.257711</td>\n      <td>-1.088294</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>0.429200</td>\n      <td>0.209911</td>\n      <td>-0.577361</td>\n      <td>0.875000</td>\n      <td>0.787273</td>\n      <td>-138.134384</td>\n      <td>-376.199280</td>\n      <td>-1.279083</td>\n      <td>-1.191719</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>0.490100</td>\n      <td>0.319152</td>\n      <td>-0.279832</td>\n      <td>0.750000</td>\n      <td>0.598985</td>\n      <td>-150.337189</td>\n      <td>-254.640549</td>\n      <td>-1.128542</td>\n      <td>-0.915180</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>0.399700</td>\n      <td>0.375513</td>\n      <td>-0.490968</td>\n      <td>0.875000</td>\n      <td>0.866481</td>\n      <td>-143.493057</td>\n      <td>-399.715668</td>\n      <td>-1.238100</td>\n      <td>-1.275257</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>0.360600</td>\n      <td>0.364163</td>\n      <td>-0.712801</td>\n      <td>1.000000</td>\n      <td>1.076964</td>\n      <td>-149.947357</td>\n      <td>-379.151489</td>\n      <td>-1.245081</td>\n      <td>-1.266284</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>0.406000</td>\n      <td>0.366054</td>\n      <td>-0.617457</td>\n      <td>0.833333</td>\n      <td>0.983512</td>\n      <td>-149.234772</td>\n      <td>-328.135620</td>\n      <td>-1.293358</td>\n      <td>-0.966292</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>0.418900</td>\n      <td>0.411516</td>\n      <td>-0.534912</td>\n      <td>0.750000</td>\n      <td>0.946428</td>\n      <td>-149.981140</td>\n      <td>-301.341217</td>\n      <td>-1.142317</td>\n      <td>-1.125973</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>0.468300</td>\n      <td>0.382339</td>\n      <td>-0.412550</td>\n      <td>0.687500</td>\n      <td>0.794889</td>\n      <td>-147.786331</td>\n      <td>-309.809875</td>\n      <td>-1.208906</td>\n      <td>-1.193800</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>0.346200</td>\n      <td>0.325091</td>\n      <td>-0.909482</td>\n      <td>0.812500</td>\n      <td>1.234573</td>\n      <td>-152.388702</td>\n      <td>-393.746521</td>\n      <td>-1.237918</td>\n      <td>-1.245112</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.368300</td>\n      <td>0.417370</td>\n      <td>-0.756348</td>\n      <td>0.937500</td>\n      <td>1.173718</td>\n      <td>-143.719940</td>\n      <td>-343.813477</td>\n      <td>-1.251107</td>\n      <td>-1.339180</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>0.304200</td>\n      <td>0.438216</td>\n      <td>-0.886324</td>\n      <td>0.937500</td>\n      <td>1.324540</td>\n      <td>-162.141113</td>\n      <td>-400.980591</td>\n      <td>-1.267723</td>\n      <td>-1.131043</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>0.443800</td>\n      <td>0.397351</td>\n      <td>-0.520221</td>\n      <td>0.750000</td>\n      <td>0.917572</td>\n      <td>-139.356964</td>\n      <td>-306.250580</td>\n      <td>-1.172100</td>\n      <td>-1.148610</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>0.322700</td>\n      <td>0.389728</td>\n      <td>-0.974791</td>\n      <td>0.937500</td>\n      <td>1.364519</td>\n      <td>-139.659531</td>\n      <td>-353.184967</td>\n      <td>-1.095496</td>\n      <td>-1.307755</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>0.358600</td>\n      <td>0.448049</td>\n      <td>-0.846820</td>\n      <td>0.937500</td>\n      <td>1.294868</td>\n      <td>-156.766632</td>\n      <td>-348.561920</td>\n      <td>-1.307899</td>\n      <td>-1.292330</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>0.433300</td>\n      <td>0.420929</td>\n      <td>-0.469103</td>\n      <td>0.875000</td>\n      <td>0.890033</td>\n      <td>-132.845123</td>\n      <td>-274.581207</td>\n      <td>-1.150017</td>\n      <td>-1.162663</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>0.430000</td>\n      <td>0.495349</td>\n      <td>-0.507201</td>\n      <td>0.937500</td>\n      <td>1.002551</td>\n      <td>-140.612061</td>\n      <td>-243.515167</td>\n      <td>-1.121528</td>\n      <td>-0.951444</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>0.365100</td>\n      <td>0.584401</td>\n      <td>-0.626796</td>\n      <td>0.875000</td>\n      <td>1.211197</td>\n      <td>-140.827820</td>\n      <td>-300.443909</td>\n      <td>-1.152623</td>\n      <td>-0.964789</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>0.431900</td>\n      <td>0.363202</td>\n      <td>-0.654869</td>\n      <td>0.812500</td>\n      <td>1.018072</td>\n      <td>-138.463745</td>\n      <td>-279.260590</td>\n      <td>-1.170770</td>\n      <td>-0.883478</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>0.340600</td>\n      <td>0.400370</td>\n      <td>-0.996350</td>\n      <td>0.875000</td>\n      <td>1.396720</td>\n      <td>-155.171387</td>\n      <td>-368.187317</td>\n      <td>-1.266171</td>\n      <td>-1.361557</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.370900</td>\n      <td>0.575385</td>\n      <td>-0.729561</td>\n      <td>0.750000</td>\n      <td>1.304947</td>\n      <td>-147.728088</td>\n      <td>-315.030212</td>\n      <td>-1.222662</td>\n      <td>-1.104552</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>0.302600</td>\n      <td>0.464433</td>\n      <td>-1.271384</td>\n      <td>0.875000</td>\n      <td>1.735817</td>\n      <td>-138.541840</td>\n      <td>-369.538025</td>\n      <td>-1.186351</td>\n      <td>-1.196984</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>0.496800</td>\n      <td>0.525029</td>\n      <td>-0.246985</td>\n      <td>0.750000</td>\n      <td>0.772014</td>\n      <td>-126.866226</td>\n      <td>-244.628189</td>\n      <td>-1.094701</td>\n      <td>-1.283910</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>0.244300</td>\n      <td>0.459704</td>\n      <td>-1.432198</td>\n      <td>1.000000</td>\n      <td>1.891902</td>\n      <td>-139.395248</td>\n      <td>-386.192566</td>\n      <td>-1.122655</td>\n      <td>-1.047834</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>0.318500</td>\n      <td>0.528077</td>\n      <td>-1.153749</td>\n      <td>0.812500</td>\n      <td>1.681825</td>\n      <td>-149.860916</td>\n      <td>-379.619537</td>\n      <td>-1.172553</td>\n      <td>-1.237448</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.252900</td>\n      <td>0.601788</td>\n      <td>-1.334833</td>\n      <td>0.937500</td>\n      <td>1.936621</td>\n      <td>-145.739304</td>\n      <td>-390.666473</td>\n      <td>-1.192125</td>\n      <td>-1.202278</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>0.408100</td>\n      <td>0.506723</td>\n      <td>-0.589968</td>\n      <td>0.875000</td>\n      <td>1.096691</td>\n      <td>-133.985840</td>\n      <td>-284.382996</td>\n      <td>-1.133240</td>\n      <td>-0.990447</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>0.301600</td>\n      <td>0.524862</td>\n      <td>-1.058419</td>\n      <td>0.937500</td>\n      <td>1.583280</td>\n      <td>-139.412857</td>\n      <td>-353.463989</td>\n      <td>-1.129639</td>\n      <td>-1.134048</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>0.313800</td>\n      <td>0.604554</td>\n      <td>-0.958263</td>\n      <td>0.937500</td>\n      <td>1.562816</td>\n      <td>-148.119949</td>\n      <td>-340.024689</td>\n      <td>-1.180235</td>\n      <td>-1.084232</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>0.380500</td>\n      <td>0.536272</td>\n      <td>-0.884028</td>\n      <td>0.687500</td>\n      <td>1.420300</td>\n      <td>-145.263931</td>\n      <td>-351.973755</td>\n      <td>-1.114204</td>\n      <td>-1.119135</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.333500</td>\n      <td>0.635923</td>\n      <td>-0.885507</td>\n      <td>0.937500</td>\n      <td>1.521430</td>\n      <td>-142.038910</td>\n      <td>-338.598816</td>\n      <td>-1.163725</td>\n      <td>-1.022014</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>0.332200</td>\n      <td>0.508571</td>\n      <td>-1.084401</td>\n      <td>0.812500</td>\n      <td>1.592972</td>\n      <td>-136.127548</td>\n      <td>-339.746704</td>\n      <td>-1.158166</td>\n      <td>-1.246409</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>0.388500</td>\n      <td>0.526989</td>\n      <td>-1.032563</td>\n      <td>0.812500</td>\n      <td>1.559551</td>\n      <td>-159.558411</td>\n      <td>-325.432007</td>\n      <td>-1.162300</td>\n      <td>-1.124975</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>0.382100</td>\n      <td>0.593629</td>\n      <td>-0.844126</td>\n      <td>0.875000</td>\n      <td>1.437755</td>\n      <td>-152.335373</td>\n      <td>-267.283752</td>\n      <td>-1.244463</td>\n      <td>-1.167670</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>0.231200</td>\n      <td>0.658068</td>\n      <td>-1.654762</td>\n      <td>0.937500</td>\n      <td>2.312830</td>\n      <td>-146.871277</td>\n      <td>-416.791687</td>\n      <td>-1.189446</td>\n      <td>-1.271111</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.171700</td>\n      <td>0.570950</td>\n      <td>-1.990136</td>\n      <td>1.000000</td>\n      <td>2.561086</td>\n      <td>-149.672699</td>\n      <td>-413.781372</td>\n      <td>-1.149699</td>\n      <td>-1.112322</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>0.290900</td>\n      <td>0.564804</td>\n      <td>-1.516797</td>\n      <td>0.875000</td>\n      <td>2.081601</td>\n      <td>-145.937897</td>\n      <td>-373.437500</td>\n      <td>-1.146218</td>\n      <td>-1.332915</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>0.251400</td>\n      <td>0.663168</td>\n      <td>-1.389860</td>\n      <td>0.937500</td>\n      <td>2.053029</td>\n      <td>-145.672195</td>\n      <td>-381.710205</td>\n      <td>-1.142721</td>\n      <td>-1.262968</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>0.269300</td>\n      <td>0.685866</td>\n      <td>-1.258480</td>\n      <td>0.937500</td>\n      <td>1.944346</td>\n      <td>-141.846832</td>\n      <td>-347.974792</td>\n      <td>-1.200100</td>\n      <td>-1.030992</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>0.272100</td>\n      <td>0.701774</td>\n      <td>-1.330954</td>\n      <td>0.937500</td>\n      <td>2.032728</td>\n      <td>-133.499496</td>\n      <td>-352.765564</td>\n      <td>-1.079285</td>\n      <td>-0.928368</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.329900</td>\n      <td>0.662138</td>\n      <td>-0.793072</td>\n      <td>1.000000</td>\n      <td>1.455210</td>\n      <td>-139.685867</td>\n      <td>-300.743439</td>\n      <td>-1.215120</td>\n      <td>-1.072016</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>0.259200</td>\n      <td>0.688184</td>\n      <td>-1.379322</td>\n      <td>0.875000</td>\n      <td>2.067506</td>\n      <td>-152.226440</td>\n      <td>-342.537079</td>\n      <td>-1.172663</td>\n      <td>-1.114118</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>0.210300</td>\n      <td>0.648070</td>\n      <td>-1.713107</td>\n      <td>1.000000</td>\n      <td>2.361177</td>\n      <td>-149.603363</td>\n      <td>-415.899231</td>\n      <td>-1.182640</td>\n      <td>-1.246245</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>0.251200</td>\n      <td>0.509651</td>\n      <td>-1.357199</td>\n      <td>0.937500</td>\n      <td>1.866849</td>\n      <td>-144.020660</td>\n      <td>-371.776337</td>\n      <td>-1.168273</td>\n      <td>-1.068493</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>0.227300</td>\n      <td>0.730915</td>\n      <td>-1.601626</td>\n      <td>0.875000</td>\n      <td>2.332542</td>\n      <td>-141.616943</td>\n      <td>-405.457916</td>\n      <td>-1.144101</td>\n      <td>-1.064909</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.254400</td>\n      <td>0.568322</td>\n      <td>-1.678283</td>\n      <td>0.812500</td>\n      <td>2.246605</td>\n      <td>-145.199921</td>\n      <td>-428.177307</td>\n      <td>-1.226986</td>\n      <td>-1.173273</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>0.143600</td>\n      <td>0.587646</td>\n      <td>-2.250242</td>\n      <td>0.875000</td>\n      <td>2.837888</td>\n      <td>-160.546082</td>\n      <td>-492.212402</td>\n      <td>-1.296333</td>\n      <td>-1.162810</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>0.302600</td>\n      <td>0.637788</td>\n      <td>-1.244109</td>\n      <td>0.875000</td>\n      <td>1.881897</td>\n      <td>-152.455078</td>\n      <td>-354.778900</td>\n      <td>-1.202918</td>\n      <td>-1.128239</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>0.377900</td>\n      <td>0.564029</td>\n      <td>-1.034655</td>\n      <td>0.812500</td>\n      <td>1.598684</td>\n      <td>-139.676361</td>\n      <td>-338.937134</td>\n      <td>-1.146460</td>\n      <td>-1.171754</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>0.252600</td>\n      <td>0.687204</td>\n      <td>-1.641562</td>\n      <td>0.812500</td>\n      <td>2.328765</td>\n      <td>-135.713135</td>\n      <td>-386.085236</td>\n      <td>-1.101935</td>\n      <td>-1.111957</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.244300</td>\n      <td>0.593190</td>\n      <td>-1.615595</td>\n      <td>0.875000</td>\n      <td>2.208785</td>\n      <td>-138.856369</td>\n      <td>-406.565491</td>\n      <td>-1.164386</td>\n      <td>-1.168320</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>101</td>\n      <td>0.281300</td>\n      <td>0.553637</td>\n      <td>-1.323640</td>\n      <td>0.937500</td>\n      <td>1.877277</td>\n      <td>-142.715546</td>\n      <td>-345.961700</td>\n      <td>-1.149917</td>\n      <td>-0.975954</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>102</td>\n      <td>0.208900</td>\n      <td>0.721759</td>\n      <td>-2.076039</td>\n      <td>0.875000</td>\n      <td>2.797798</td>\n      <td>-152.502960</td>\n      <td>-467.122131</td>\n      <td>-1.183494</td>\n      <td>-1.157909</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>103</td>\n      <td>0.276100</td>\n      <td>0.531724</td>\n      <td>-1.511663</td>\n      <td>0.937500</td>\n      <td>2.043387</td>\n      <td>-152.870834</td>\n      <td>-373.206787</td>\n      <td>-1.154625</td>\n      <td>-1.141239</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>104</td>\n      <td>0.360600</td>\n      <td>0.800747</td>\n      <td>-0.673761</td>\n      <td>0.937500</td>\n      <td>1.474508</td>\n      <td>-132.838364</td>\n      <td>-298.967377</td>\n      <td>-1.158717</td>\n      <td>-1.126352</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>105</td>\n      <td>0.311700</td>\n      <td>0.590691</td>\n      <td>-1.251594</td>\n      <td>0.937500</td>\n      <td>1.842285</td>\n      <td>-144.355469</td>\n      <td>-345.931274</td>\n      <td>-1.128990</td>\n      <td>-1.130202</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>106</td>\n      <td>0.308600</td>\n      <td>0.667275</td>\n      <td>-1.381558</td>\n      <td>0.812500</td>\n      <td>2.048833</td>\n      <td>-147.618774</td>\n      <td>-341.651520</td>\n      <td>-1.161017</td>\n      <td>-1.015975</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>107</td>\n      <td>0.397800</td>\n      <td>0.587595</td>\n      <td>-0.730973</td>\n      <td>0.812500</td>\n      <td>1.318568</td>\n      <td>-124.217026</td>\n      <td>-293.623962</td>\n      <td>-0.997947</td>\n      <td>-1.119935</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>108</td>\n      <td>0.348900</td>\n      <td>0.484650</td>\n      <td>-1.103454</td>\n      <td>0.812500</td>\n      <td>1.588104</td>\n      <td>-132.740326</td>\n      <td>-315.109070</td>\n      <td>-1.127130</td>\n      <td>-1.223405</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>109</td>\n      <td>0.135200</td>\n      <td>0.607226</td>\n      <td>-2.463784</td>\n      <td>0.937500</td>\n      <td>3.071010</td>\n      <td>-139.020416</td>\n      <td>-465.901184</td>\n      <td>-1.142421</td>\n      <td>-1.167273</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.302900</td>\n      <td>0.731206</td>\n      <td>-1.314369</td>\n      <td>0.812500</td>\n      <td>2.045576</td>\n      <td>-135.700027</td>\n      <td>-346.498108</td>\n      <td>-1.165508</td>\n      <td>-1.287825</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>111</td>\n      <td>0.262300</td>\n      <td>0.792181</td>\n      <td>-1.411622</td>\n      <td>0.875000</td>\n      <td>2.203803</td>\n      <td>-154.061783</td>\n      <td>-359.768616</td>\n      <td>-1.199060</td>\n      <td>-1.087324</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>112</td>\n      <td>0.426800</td>\n      <td>0.650170</td>\n      <td>-0.714123</td>\n      <td>1.000000</td>\n      <td>1.364293</td>\n      <td>-136.589310</td>\n      <td>-296.079956</td>\n      <td>-1.203407</td>\n      <td>-0.983404</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n  </tbody>\n</table><p>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "TrainOutput(global_step=112, training_loss=0.451698374136218, metrics={'train_runtime': 988.4785, 'train_samples_per_second': 1.795, 'train_steps_per_second': 0.113, 'total_flos': 0.0, 'train_loss': 0.451698374136218, 'epoch': 2.0})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "%%capture\n",
        "!pip install rouge-score bert-score"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "print(\"=\"*80)\n",
        "print(\"LOADING TEST DATASET\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# The test dataset is already in raw_datasets from the data prep step\n",
        "test_dataset = raw_datasets[\"test\"]\n",
        "\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n",
        "print(f\"Sample from test set:\")\n",
        "print(test_dataset[0])\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "LOADING TEST DATASET\n",
            "================================================================================\n",
            "Test dataset size: 47\n",
            "Sample from test set:\n",
            "{'chosen': '<|begin_of_text|><|start_header_id|>assistant<|end_header_id|>\\n\\nSide-tuning adapts a pre-trained network by training a lightweight \"side\" network that is fused with the (unchanged) pre-trained network using a simple additive process.<|eot_id|>', 'rejected': '<|begin_of_text|><|start_header_id|>assistant<|end_header_id|>\\n\\n1/4, 1/2, and the full parameters of a ResNet-50 for both the base and side networks. We find that the best performance is had when the side network is large and the base is small. This is because the base is only used to provide a coarse estimate, and a large base network will produce a coarse estimate that requires a larger side network to overcome. The optimal \u03b1. In the supplementary material we show that the optimal \u03b1 is not always 0.5. For instance, when the base is a denoising network and the target is curvature, \u03b1 = 0.6 performs better than 0.5. This is because the optimal \u03b1 is task-dependent. We also show that the optimal \u03b1 can be recovered from a small amount of training data. We have presented a simple method for network adaptation that is robust to catastrophic forgetting and intransigence. It is straightforward to implement, requires only a small amount of additional computation, and is well-suited to a variety of network architectures. Moreover, it is an example of an additive learning approach that does not suffer from the basic problems of catastrophic forgetting and rigidity. We have shown that it performs well on a variety of tasks and domains, and that it is<|eot_id|>', 'prompt': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are an engaging writer.\\n\\nA spotlight is a short narrative teaser written as a single paragraph. It highlights ONE intriguing angle and sparks curiosity without summarizing.\\n\\nWrite a spotlight ( 1-2 sentences).\\n\\n### Document:\\nWhen training a neural network for a desired task, one may prefer to adapt a pretrained network rather than start with a randomly initialized one -- due to lacking enough training data, performing lifelong learning where the system has to learn a new task while being previously trained for other tasks, or wishing to encode priors in the network via preset weights. The most commonly employed approaches for network adaptation are fine-tuning and using the pre-trained network as a fixed feature extractor, among others. In this paper we propose a straightforward alternative: Side-Tuning. Side-tuning adapts a pretrained network by training a lightweight \"side\" network that is fused with the (unchanged) pre-rained network using a simple additive process. This simple method works as well as or better than existing solutions while it resolves some of the basic issues with fine-tuning, fixed features, and several other common baselines. In particular, side-tuning is less prone to overfitting when little training data is available, yields better than using a fixed feature extractor, and doesn\\'t suffer from catastrophic forgetting in lifelong learning. We demonstrate the performance of side-tuning under a diverse set of scenarios, including lifelong learning (iCIFAR, Taskonomy), reinforcement learning, imitation learning (visual navigation in Habitat), NLP question-answering (SQuAD v2), and single-task transfer learning (Taskonomy), with consistently promising . The goal of side-tuning is to capitalize on a pretrained model to better learn one or more novel tasks. By design, side-tuning does so without degrading performance of the base model. The framework is straightforward: it assumes access to the frozen base model B: X \u2192 Y that maps inputs into some representation space that is shared between the base task and the current (target) task. This representation space is flexible and could either be a latent space (e.g. in R N) or actual model predictions. Side-tuning then learns a side model S: X \u2192 Y, so that the representations for the target task are R(x) B(x) \u2295 S(x), fine-tuning adapts too easily and forgets old information. Side-tuning is a simple method to address these limitations. for some combining operation \u2295. We use a learned alpha-blending, a \u2295 b \u03b1a + (1 \u2212 \u03b1)b for this purpose (other options are discussed in Section 3.0.3). Certain pre-set curricula of \u03b1 reduce the side-tuning framework to: fine-tuning, feature extration, and stage-wise training (see Fig. 3, right). Hence those can be viewed as special cases of the general side-tuning framework. Also, other curricula suggest (e.g.) a maximum a posteriori estimator that integrates the B(x) prior with the evidence from S(x). Side-tuning is an example of an additive learning approach as it adds (strategically placed) parameters for each new task. Fixed feature extraction would be a simple example of an additive approach with zero new parameters. As a , fixed features are don\\'t adapt the base network over the lifetime of the agent. A number of existing approaches address this by learning new parameters (the number of which scales with the size of the base network) for each new task (e.g. . Unlike these approaches, side-tuning places no constraints on the structure of the side network, allowing the parameters to be strategically allocated. In particular, side-tuning can use tiny networks when the base requires only minor updates. By adding fewer parameters per task, side-tuning can learn more tasks before the model grows large enough to require parameter consolidation. These approaches stand in contrast to most existing methods for incremental learning, which do not increase the number of parameters over time and instead gradually fill up the capacity of a large base model. For example, fine-tuning updates all the parameters. A large body of constraint-based methods focus on how to regularize these updates in order to prevent inter-task interference . Side-tuning does not require such regularization since the additive structure means inter-task interference is not possible. We compare side-tuning to alternative approaches on both the iCIFAR and Taskonomy datasets. iCIFAR consists of ten distinct 10-class image classification problems. Taskonomy covers multiple tasks of varied complexity from across computer vision (surface normal and depth estimation, edge detection, image 1000-way classification, etc.). On these datasets, side-tuning uses side networks that are much smaller than the base. Consequently, even without consolidation, side-tuning uses fewer learnable parameters than the alternative methods. This remarkably simple approach deals with the key challenges of incremental learning. Namely, it does not suffer from either: \u2022 Catastrophic forgetting: which is the tendency of a network to abruptly lose previously learned knowledge upon learning new information. We show this in Section 4.2.1. \u2022 Rigidity: where networks become increasingly unable to adapt to new problems as they accrue constraints from previous problems. We explore this in Section 4.2.2. Side-tuning avoids these problems while remaining highly performant, which we demonstrate in Section 4.2.3. Broadly speaking, network adaptation methods either overwrite existing knowledge (substitutive methods) or save it and add new parameters (additive learning). In incremental (lifelong) learning, substitutive methods like fine-tuning are at risk of forgetting early tasks. To prevent forgetting, existing methods add non-interference constraints that eventually slow down learning or they force tasks to be independent which prevents reusing knowledge. Side-tuning is an additive approach that performs well and scales well, and, by design, does not suffer from the aforementioned problems. We show this experimentally on various tasks and datasets, including iCIFAR (b), Habitat , SQuAD v2 , and Taskonomy . In the remainder of this section we overview sidetuning\\'s connection to related fields. Network Adaptation modifies an existing network to solve a single new task. The most common approach is to update some or all of the network weights (fine-tuning), possibly by adding constraints. Other approaches freeze the weights and modulate the output by learning additional task-specific parameters. An economical approach is to use off-the-shelf-features with one or more readout layers . Other approaches use custom connection schema. instead modulate the output by applying learned weight masks. These approaches, like side-tuning, are examples of additive learning. Incremental learning has the objective of learning a sequence of tasks T 1,..., T m and, at the end of training, performing well on the entire set. The sequential presentation creates two problems for neural networks. The first is catastrophic forgetting and the second is learning speed, which should not slow down as more tasks are added. Because of these issues (and scaling), not every network adaptation approach lends itself to incremental learning. Standard incremental learning approaches avoid catastrophic forgetting by imposing constraints how the parameters are updated. relegates each task to approximately orthogonal subspaces.;; add a parameter regularization term per task. Imposing constraints tends to slow down learning on later tasks (intransigence,) while making tasks independent ignores the possibility for useful transfer from relevant previous tasks. Additive methods in general, and side-tuning in particular, have the advantage that they do not suffer from catastrophic forgetting and are capable of transfer. However, additive methods have not been much explored because it is assumed that they either have poor performance or scale poorly. We show that side-tuning has good performance and scaling, and demonstrate the additive advantages experimentally; using the iCIFAR and Taskonomy datasets. Meta-learning seeks to create agents that rapidly adapt to new problems by first training on tasks sampled from a standing distribution of tasks. Side-tuning is fundamentally compatible with this formulation and with existing approaches (e.g.). Moreover, recent work suggests that these approaches work primarily by feature adaptation rather than rapid learning , and feature adaptation is also the motivation for our method. Residual Learning exploits the fact that it is sometimes easier to approximate a difference rather than the original function. This has been successfully used in ResNets and robotics, where residual RL learns a single task by first training a coarse policy (e.g. behavior cloning) and then training a residual network on top (using RL). Additive Learning in Other Literature. Concepts similar to additive learning have been studied in a number of fields. For instance, developing infants are hypothesized to learn separate, discontinuous, and context-dependent perception systems during development . Adults are able to rapidly learn new affordances, but only when those are minor updates to familiar, well-practiced systems . On a more fine-grained scale, there are areas of functional specificity within the brain , including wholly separate pathways where output is mutually conditioned on one another . Side-tuning learns a side model S(X) and combines this with a base model B(x) so that the representations for the target task are computed as R(x) B(x) \u2295 S(x). The base model B(x) provides some core cognition or perception, and we put no restrictions on how B(x) is computed. We never update B(x), and in our approach it has zero learnable parameters. In general B(x) could be nonparametric, and it might not be optimized for any particular task. We consider several choices for B(x) in Section 4.4, but the simplest choice is just a pretrained network. Unlike the base model, the side network S(x) is updated during training; learning a residual that we apply on top of the base encoding. Iteratively learning residuals for a single task is known as gradient boosting (see Section 4.4 for a comparison). Side-tuning is instead focused on learning multiple tasks. One crucial component of the framework is that the complexity of the side network can scale to the difficulty of the problem at hand. When the base is relevant and requires only a minor update, a very small network can suffice. Section 4.4 explores the effect of network size, how that changes with the choice of base and target tasks. While the side network can be initialized using a variety of methods, we initialize the side network with a copy of the base network. When the forms of the base and side networks differ, we initialize the side network with weights distilled from the base network using knowledge distillation . We test alternatives in Section 4.4. The final side-tuning representation is a combination, B(x) \u2295 S(x). What should \u2295 be? Side-tuning admits several options for this combination operator. Choosing max yields the subsumption architecture. Concatenation and summation are other viable choices. We observe that alpha blending, a \u2295 b \u03b1a + (1 \u2212 \u03b1)b, works well in practice. Alpha blending preserves the dimensions of the inputs and is simpler than concatenation. In fact, concatenation followed by a channel-collapsing operation (e.g. 1x1 convolution) is a strict generalization of alpha-blending. While simple, alpha blending is expressive enough that it encompasses several common transfer learning approaches. As shown in Figure 3 and when the side network is the same as the base, sidetuning is equivalent to feature extraction when \u03b1 = 1. When \u03b1 = 0, side-tuning is instead equivalent to fine-tuning. If we allow \u03b1 to vary during training (which we generally do), then switching \u03b1 from 1 to 0 is equivalent to the common (stage-wise) training curriculum in RL where a policy is trained on top of some fixed features that are unlocked partway through training. Another notable curriculum is \u03b1(N) = k k+N for k > 0 (hyperbolic decay). In this curriculum, \u03b1 controls the weighting of the prior (B(x)) with the learned estimate (S(x)), and the weight of the evidence scales with the amount of data. This curriculum is suggestive of a maximum a posteriori estimate and, like the MAP estimate, it converges to the MLE (fine-tuning, \u03b1 = 0). Finally, \u03b1 can treated as a learnable free parameter that determines how heavily to weight the base model. In practice, the value of \u03b1 correlates with task relevance (see Section 4.4). When minimizing estimation error there is often a tradeoff between the bias and variance contributions . Choosing between feature extraction or fine-tuning exemplifies this dilemma. Feature extraction (\u03b1 = 0) locks the weights and corresponds to a point-mass prior that, unless the weights are already optimal, yields a very biased estimator. In fact, the estimator allows no adaptation to new evidence and is asymptotically inconsistent. On the other hand, fine-tuning (\u03b1 = 1), is an uninformative prior yielding a low-bias high-variance estimator. With enough data, fine-tuning can produce better estimates, but this usually takes more data than feature extraction. Side-tuning addresses both the these problems. It reduces variance by including the fixed features in the representation, and it is consistent because it allows updating via the residual side network. While \u03b1 provides a way to control the importance of the prior, another natural approach for enforcing a prior is to penalize deviations from the original feature representation. Typically, it is easier to specify meaningful explicit priors on outputs (e.g. L2 for pixels) than on the latent representations, which can be difficult if not impossible to interpret. As long as the decoder D: Y \u2192 A is differentiable, any distance measure on the outputs can be pulled back through the decoder and into the latent space. This induced distance d D on the latent representations is called the pullback metric in differential geometry, and in deep learning it is called the perceptual loss . This may be a useful method for knowledge transfer when (i) the previous task is relevant to the new task and (ii) there is limited training data. A recent successful application of this approach would be the auxiliary losses in GPT , though we did not find it effective. Perceptual regularization is often used to dampen catastrophic forgetting. For example, Elastic Weight Consolidation uses a diagonalized second-order Taylor expansion of the expectation of the pullback metric. Learning Without Forgetting uses a decoder-based approach that can be interpreted as jointly updating both the base network and the pullback metric. We show that such regularization does not fully address the problem of catastrophic forgetting (Section 4.2.1). Side-tuning avoids catastrophic forgetting by design (as the base network is never updated). Network adaptability is the sole criterion only if we care we solely about raw performance on a single target task. In reality we often care about the performance on both the current and previous tasks. This is the case for incremental learning, where we want an agent that can learn a sequence of tasks T 1,..., T m and, at the end, is capable of reasonable performance across the entire set. Thus, catastrophic forgetting becomes a major issue. In our experiments we dedicate one new side network to each new task and train it independently of the earlier side networks. In principle, learning of new tasks can benefit from all the side networks learned in previous tasks (i.e. the nth task can use all n \u2212 1 previous tasks). Since we do not make use of this available information, our should be considered as a lower bound on side-tuning performance. We show that this simple approach provides a strong baseline for incremental learning-outperforming existing approaches in the literature while using fewer parameters on more tasks (in Section 4.2). Side-tuning takes an additive learning approach to incremental learning, which means that alreadylearned components are never updated and performance across the whole set can only increase as the agent sees more tasks. This monotonicity is the key property of the additive family of algorithms. It is worth repeating that there is No Catastrophic Forgetting in Additive Learning and a typical learning curve for one of the tasks is shown in Figure 4. Furthermore, because our implementation of side-tuning treats problems independently of their order in the sequence (always using the fixed base and one side network), side-tuning incurs no rigidity during training. We show this in Section 4.2.2. Side-tuning naturally handles other continuous learning scenarios besides incremental learning. A related problem is that of continuous adaptation, where the agent needs to perform well (e.g. minimizing regret) on a stream of tasks with undefined boundaries and where there might very little data per task and no task repeats. As we show in Section 4.2, inflexibility becomes a serious problem for constraint-based methods and task-specific performance declines after learning more than a handful of tasks. Moreover, continuous adaptation requires an online method as task boundaries must be detected and data cannot be replayed (e.g. to generate constraints for EWC). Side-tuning could be applied to continuous adaptation by keeping a small working memory of cheap side networks that constantly adapt the base network to the input task. These side networks are small, easy to train, and when one of the networks begins performing poorly (e.g. signaling a distribution shift) that network can simply be discarded. This is an online approach, and online adaptation with small cheap networks has found recent success in (e.g.). In the first section we show that side-tuning compares favorably to existing incremental learning approaches on both iCIFAR and the more challenging Taskonomy dataset. We then extend to multiple domains (computer vision, RL, imitation learning, NLP) in the simplified (transfer learning) scenario for N = 2 tasks. Finally, we interpret side-tuning in a series of analysis experiments. We provide comparisons of side-tuning against the following methods: The network is given a good random initialization and then trained normally. The base network is used as-is and is not updated during training. Fine-tuning: An umbrella term that encompasses a variety of techniques, we consider a more narrow definition where pretrained weights are used as initialization and then training proceeds as in scratch. A constraint-based incremental learning approach from. We use the formulation from which scales better-, giving an advantage to EWC since otherwise we could use a larger side-tune network and maintain parameter parity. Parameter Superposition (PSP): A parameter-masking approach from. Progressive Neural Network (PNN): A network adaptation approach from. Independent: Each task uses a network trained independently for the target task. This method uses far more learnable parameters than all the alternatives (e.g. saving a separate ResNet-50 for each task) and achieves very strong performance. Due to the scaling, it is generally not considered an incremental learning method. incremental learning experiments for three tasks on Taskonomy (left) and iCIFAR dataset (right). The fact that side-tuning losses are flat after training (as we go right) shows that it does not forget previously learned tasks. Similarly, the performance remains consistent even on later tasks (as we go down), showing that side-tuning does not become rigid. Alternative methods clearly forget (e.g. PSP) and/or become rigid (e.g. EWC). In Taskonomy, PNN and Independent are hidden under Sidetune. In iCIFAR, Sidetune (A) merges base and side information with a multilayer perceptron (adapter). On both the Taskonomy dataset and incremental CIFAR (iCIFAR, a), side-tuning outperforms existing incremental learning approaches while using fewer parameters 1. Moreover, the performance gap is larger on more challenging datasets. Taskonomy includes labels for multiple computer vision tasks including 2D (e.g. edge detection), 3D (e.g. surface normal estimation), and semantic (e.g. object classification) tasks. We first selected the twelve tasks that make predictions from a single RGB image, and then created an incremental learning setup by selecting a random order in which to learn these tasks (starting with curvature). As images are 256x256 we use a ResNet-50 for the base network and a 5-layer convolutional network for the side-tuning side network. The number of learnable network parameters used across all tasks is 24.6M for EWC and PSP, and 11.0M for side-tuning 2. iCIFAR. First, we pretrain the base network (ResNet-44) on CIFAR-10. Then the 10 subsequent tasks are formed by partitioning CIFAR-100 classes into 10 disjoint sets of 10-classes each. We train on each subtask for 20k steps before moving to the next one. Our state-of-the-art substitutive baselines (EWC and PSP) update the base network for each task (683K parameters), while sidetuning updates a four layer convolutional network per task (259K parameters after 10 tasks). As expected, there is no catastrophic forgetting in side-tuning. Figure 6 shows that the error for side-tuning does not increase after training (blue shaded region), while it increases sharply for the other methods on both Taskonomy and iCIFAR. The difference is meaningful, and Figure 5 shows sample predictions from side-tuning vs. EWC for a few tasks during and after training. As is evident from the bottom rows, EWC exhibits catastrophic forgetting on all tasks (worse image quality as we move right). In contrast, side-tuning (top) shows no forgetting and the final predictions are significantly closer to the ground-truth (boxed red). Side-tuning learns later tasks as easily as the first, while constraint-based methods such as EWC stagnate. The predictions for later tasks such as surface normals (in Figure 5) are significantly better using side-tuning-even immediately after training and before any forgetting can occur. Figure 7: Rigidity and average rank on Taskonomy and iCiFAR. From left: Side-tuning always learns new tasks easily; EWC becomes increasingly unable to learn new tasks as training progresses. Center: The same trend holds on iCIFAR, and the average rigidity is zero for side-tuning (and almost zero for PSP). Right: Side-tuning outperforms alternatives on both datasets, achieving a significantly better average rank on all tasks. Figure 7 quantifies this slowdown. We measure rigidity as the log-ratio of the actual loss or the ith task over the loss when that task is instead trained first in the sequence. As expected, side-tuning experiences zero slowdown on both datasets. For EWC, the increasing constraints make learning new tasks increasingly difficult-and the log-ratio increases with the number of tasks (Taskonomy, left). It is too rigid (log-ratio > 0) even in iCIFAR, where the later tasks are similar to earlier ones. Overall, side-tuning significantly outperforms the other methods while using fewer than half the number of trainable parameters of the other methods. When the other methods use smaller networks, their performance decreases further. On both iCIFAR and Taskonomy, side-tuning achieves the best average rank (1.12 of 4 on Taskonomy, while the next best is 2.33 (PSP)). This is a direct of the fact (shown above) that side-tuning does not suffer from catastrophic forgetting or rigidity. It is not due to the fact that the sidetuning structure is specially designed for these types of image tasks; it is not (we show in Sec. 4.3 that it performs well on other domains). In fact, the much larger networks used in EWC and PSP should achieve better performance on any single task. For example, EWC produces sharper images early on in training, before it has had a chance to accumulate too many constraints (e.g. reshading in Fig. 5). But this factor was outweighed by side-tuning\\'s immunity from the effects of catastrophic forgetting and creeping rigidity. In order to address the possibility that side-tuning is somehow domain-or task-specific, we provide showing that it is well-behaved in other settings. As the concern with additive learning is mainly that it is too inflexible to learn new tasks, we compare with fine-tuning (which outperforms other lifelong learning tasks when forgetting is not an issue). For extremely limited amounts of data, feature extraction can outperform fine-tuning. We show that side-tuning generally performs as well as features or fine-tuning-whichever is better. We trained networks to perform one of three target tasks (object classification, surface normal estimation, and curvature estimation) on the Taskonomy dataset and varied the size of the training set N \u2208 {100, 4 \u00d7 10 6}. In each scenario, the base network was trained (from scratch) to predict one of the non-target tasks. The side network was a copy of the original base network. We experimented with a version of fine-tuning that updated both the base and side networks; the were similar to standard fine-tuning 3. In all scenarios, side-tuning successfully matched the adaptiveness of fine-tuning, and significantly outperformed learning from scratch, as shown in Figure 4.3. The additional structure of the frozen base did not constrain performance with large amounts of data (4M images), and side-tuning performed as well as (and sometimes slightly better than) fine-tuning. We also evaluated side-tuning on a question-answering task (SQuAD v2 ) using a non-convolutional architecture. We use a pretrained BERT model for our base, and a second for the side network 3. Unlike in the previous experiments, BERT uses attention and no convolutions. Still, side-tuning adapts to the new task just as well as fine-tuning, outperforming features and scratch (Figure 4.3). We trained an agent to navigate to a target coordinate in the Habitat environment. The agent is provided with both RGB input image and also an occupancy map of previous locations. The map does not contain any information about the environment-just previous locations. In this section we use Behavior Cloning to train an agent to imitate experts following the shortest path on 49k trajectories in 72 buildings. The agents are evaluated in 14 held-out validation buildings. Depending on the what the base network was trained on, the source task might be useful (Curvature) or harmful (Denoising) for imitating the expert and this determines whether features or learning from scratch performs best. Figure 4.3 shows that regardless of the which approach worked best, side-tuning consistently matched or beat it. Reinforcement Learning for Navigation in Habitat Using a different learning algorithm (PPO) and using direct interaction instead of expert trajectories, we observe identical trends. We trained agents directly in Habitat (74 buildings) 3. Figure 4.3 shows performance in 16 held-out buildings after 10M frames of training. Side-tuning performs comparably to the max of competing approaches. Task relevance predicts alpha \u03b1. In our experiments, we treat \u03b1 as a learnable parameter and find that the relative values of \u03b1 are predictive of emprical performance. In imitation learning (Fig. 4.3), curvature (\u03b1 = 0.557) outperformed denoising (\u03b1 = 0.252). In Taskonomy, the \u03b1 values from training on just 100 images predicted the actual transfer performance to normals in , (e.g. curvature (\u03b1 = 0.56) outperformed object classification (\u03b1 = 0.50)). For small datasets, usually \u03b1 \u2248 0.5 and the relative order, rather than the actual value is important. We showed in the previous section that side-tuning performs like the best of {features, fine-tuning, scratch} in domains with abundant or scant data. In order to test whether side-tuning could profitably synthesize the features with intermediate amounts of data, we evaluated each approach\\'s ability to learn to navigate using 49, 490, 4900, or 49k expert trajectories and pretrained denoising features. Side-tuning was always the best-performing approach and, on intermediate amounts of data (e.g. 4.9k trajectories), outperformed the other techniques (side-tune 9.3 vs. fine-tune: 7.5, features: 6.7, scratch: 6.6), Figure 9b ). Network size. Does network size matter? We find (i) If the target problem benefits from a large network (e.g. classification tasks), then performance is sensitive to side network size but not size of the base. (ii) The base network can usually be distilled to a smaller network and sidetuning will still offer advantages over alternatives. In the supplementary material we provide supporting experiments from Taskonomy using both high-and low-data settings (curvature \u2192 {obj. class, normals}, obj. class \u2192 normals), and in Habitat (RL using {curvature, denoise} \u2192 navigation). Not Boosting. Since the side network learns a residual on top of the base network, we ask: what benefits we could glean by extending side-tuning to do boosting? Although network boosting this does improve performance on iCIFAR (Figure 9a), if catastrophic forgetting is not a concern then the parameters would\\'ve been better used in a deeper network rather than many shallow networks. Initialization. A good side network initialization can yield a minor boost in performance. We found that initializing from the base network slightly outperforms a low-energy initialization 4, which slightly outperforms Xavier initialization. However, we found that these differences were not statistically significant across tasks (H 0 : pretrained = xavier; p = 0.07, Wilcoxon signed-rank test). We suspect that initialization might be more important on harder problems. We test this by repeating the analysis without the simple texture-based tasks (2D keypoint + edge detection and autoencoding) and find the difference in initialization is now significant (p = 0.01). More than just stable updates. In RL, fine-tuning often fails to improve performance. One common rationalization is that the early updates in RL are\\'high variance\\'. The usual solution is to first train using fixed features and then unfreeze the weights at some point in training (via a hyperparameter to be set). We found that this stage-wise approach performs as well (but no better than) keeping the features fixed-and side-tuning performed as well as both while being simpler than stage-wise (Fig. 9c). We tested the\\'high-variance update\\' theory by fine-tuning with both gradient clipping and an optimizer designed to prevent such high-variance updates by adaptively warming up the learning rate . This provided no benefits over vanilla fine-tuning, suggesting that the benefits of side-tuning are not solely due to gradient stabilization early in training. We have introduced the side-tuning framework, a simple yet effective approach for additive learning. Since it does not suffer from catastrophic forgetting or rigidity, it is naturally suited to incremental learning. The theoretical advantages are reflected in empirical , and side-tuning outperforms existing approaches in challenging contexts and with state-of-the-art neural networks. We further demonstrated that the approach is effective in multiple domains and with various network types. The na\u00efve approach to incremental learning used in this paper made a number of design decisions. These decisions could be analyzed and subsequently relaxed. In particular: Flexible parameterizations for side networks: Our incremental learning experiments used the same side network architecture for all subtasks. A method for automatically adapting the networks to the subtask at hand could make more efficient use of the computation and supervision. Better forward transfer: Our experiments used only a single base and single side network. Leveraging the already previously trained side networks could yield better performance on later tasks. Learning when to deploy side networks: Like most incremental learning setups, we assume that the tasks are presented in a sequence and that task identities are known. Using several active side networks in tandem would provide a natural way to detecting distribution shift. Using side-tuning to measure task relevance: We noted that \u03b1 tracked task relevance, but a more rigorous treatment of the interaction between the base network, side network, \u03b1 and final performance could yield insight into how tasks relate to one another. We test the effect of base model architecture on performance and find that the small five layer convolutional network does comparable to the ResNet-50 when using features. Rectified Adam is a method introduced to deal with destructive high variance updates at the beginning of training. We tried using this for RL but found no improvements (shown in Figure 15). We ablate over different quantities of expert trajectories. We observe that when data is scarce, features is a powerful choice whereas when data is plentiful, fine-tuning performs well. In both scenarios, side-tuning is able to perform as well as the stronger approach. In domains with very few examples, we found that side-tuning is unable to match the performance of other methods. We evaluated our setup in vision transfer for 5 images from the same building, imitation learning given 5 expert trajectories. Taskonomy Our data is 4M images on 12 single image tasks. The tasks that we use are the following: curvature, semantic segmentation, reshading, keypoints3d, keypoints2d, texture edges, occlusion edges, distance, depth, surface normals, object classification and autoencoding. The tasks were chosen in no particular special order. Our base model and side model are ResNet-50s. We pretrain on curvatures. Then, we train each task for three epochs before moving on to the next task. We use cross entropy loss for classification tasks (semantic segmentation and object classification), L2 loss for curvature and L1 loss for the other tasks. We use Adam optimizer with an initial learning rate of 1e-4, weight decay coefficient of 2e-6, gradient clipping to 1.0, and batch size of 32. We evaluate our performance on a held out set of images, both immediately after training a specific task, and after training of all the tasks are complete. iCIFAR We start by pretraining a model on CIFAR 10 (from https://github.com/ akamaster/pytorch_resnet_cifar10). Then we partition CIFAR100 into 10 distinct sets of 10 classes. Then, we train for 4 epochs on these tasks using Adam optimizer, learning rate of 1e-3, batch size of 128. We train and test on the the question answering dataset SQuAD2.0, a reading comprehension dataset consisting of 100,000 questions with 50,000 unanswerable questions. Both our base encoding and side network is a BERT transformer pretrained on a larger corpus. Finetuning trains a single BERT transfer. We use the training setup found at https://github.com/huggingface/ pytorch-transformers (train for 2 epochs at a learning rate of 3e-5) wth one caveat -we use an effective batch size of 3 (vs. their 24) due to the We borrow the experimental setup from work to be published in October 2019: We use the Habitat environment with the Gibson dataset. The dataset virtualizes 572 actual buildings, reproducing the intrinsic visual and semantic complexity of real-world scenes. We train and test our agents in two disjoint sets of buildings (Fig. ??). During testing we use buildings that are different and completely unseen during training. We use up to 72 building for training and 14 test buildings for testing. The train and test spaces comprise 15678.4m 2 (square meters) and 1752.4m 2, respectively. The agent must direct itself to a given nonvisual target destination (specified using coordinates), avoiding obstacles and walls as it navigates to the target. The maximum episode length is 500 timesteps, and the target distance is between 1.4 and 15 meters from the start. This setup is shared between imitation learning and RL, which differ in the data, architecture and optimization process. Imitation Learning We collect 49,325 shortest path expert trajectories in Habitat, 2,813,750 state action pairs. We learn a neural network mapping from states to actions. Our base encoding is a ResNet-50 and the side network is a five layer convolutional network. The representation output is then fed into a neural network policy. We train the model for 10 epochs using cross entropy loss and Adam at an initial learning rate of 2e-4 and weight decay coefficient of 3.8e-7. We initialize alpha to 0.5. Finetuning uses the same model architecture but updates all the weights. Feature extraction only uses the ResNet-50 to collect features. RL Similarly, we borrow the RL setup from the same work. In all experiments we use the common Proximal Policy Optimization (PPO) algorithm with Generalized Advan-tage Estimation. Due to the computational load of ren-dering perceptually realistic images in Gibson we are only able to use a single rollout worker and we therefore decorre-late our batches using experience replay and off-policy vari-ant of PPO. The formulation is similar to Actor-Critic with Experience Replay (ACER) in that full trajectories are sampled from the replay buffer and reweighted using the first-order approximation for importance sampling. During training, the agent receives a large one-time reward for reaching the goal, a positive reward proportional to Euclidean distance toward the goal and a small negative reward each timestep. The maximum episode length is 500 timesteps, and the target distance is between 1.4 and 15 meters from the start. Due to this paradigms\\' compute and memory constraints, it would be difficult for us to use large architectures for this setting. Thus, our base encoding is a five layer convolutional network distilled from the trained ResNet-50. Our side network is also a five layer convoultional network. Finetuning is handled the same way -update all the weights in this setup. Feature extraction uses the five layer network to collect features. Low energy initialization In classical teacher student distillation, the student is trained to minimize the distance between its output and the teacher\\'s output. In this setting, we minimize the distance between the teacher\\'s output and the summation of the student\\'s output and the teacher\\'s output). The output space may have a different geometry than that of the input space and this would allow us to work with A.5 ADDITIONAL ANALYSIS We provide alternative perspectives and additional insights for our lifelong learning tasks. iCIFAR In Fig. 7 (right), we see that the average rank of side-tuning higher than that of PNN. We find that side-tuning can bridge this gap with a multilayer perceptron (adapter) to merge the base and side networks. This is a common practice in PNN. In Fig. 20, we see with the adapter network, the two methods are very similar when measuring classification error. I n d e p. P N N S i d e t u n e (A) S i d e t u n e E W C P S P F i n e t u n e In d e p. S id e t u n e P N N 3 P N N F in e t u n e E W C P S P In d e p. S id e t u n e P N N 3 P N N F in e t u n e E W C P S P In d e p. S id e t u n e P N N 3 P N N F in e t u n e E W C P S P Taskonomy In Fig. 7 (right), we found that the ranking of our method is better than all other methods, including PNN. By altering the connections in the PNN, we found an alternate (PNN3) that has comparable performance to side-tuning. In 21, we show all the losses normalized by single task loss (independent) as presented in. The quantitative performance of our method outperforms all other methods and matches closely with that of PNN. We qualitatively show in Figures 22, 23, 24, that these methods are comparable in performance. An alternative perspective views these methods as various fusions between some base information and new side information. In this framework, side-tuning is a late-fusion approach whereas PNN is a distributed-fusion approach. In Fig. 25, we compare various fusion methods in iCIFAR and find that late fusion performs better than early fusion and comparable to if not better than distributed fusion. We run this analysis in Taskonomy as well -while the loss values differ somewhat, we find that the qualitative seen in Figures 26, 27, 28 are rather similar. Thus, we conclude that the methods do not vary much. Distributed and early fusion require knowledge about the structure of how the information is computed. This is something late fusion is agnostic to and it can consider each information column a black box -this is useful in the case that your base information is NOT a neural network, perhaps non-parametric. In Fig. A.5.2, we show that side-tuning can effectively use ground truth curvature as a base for lifelong learning whereas all the methods we compare against cannot use this information. Specifically, we downsample the curvature image and stack it into the same dimensions as the side output. Side-tuning with ground truth curvature achieves a better rank on the Taskonomy dataset than all other methods and comparable performance. GT Late Dist Early Figure 29: Sidetuning can be used successfully even with black-box side information. When the base information comes from a black-box process for which we have no other information, sidetuning can still be used (and performance improves vis-a-vis not using the inputs, and vs using inputs generated from a neural network). Existing lifelong learning approaches have no standard way to make use of this type of information.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"LOADING BASE MODEL FOR COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "# Load the base model (without LoRA adapters)\n",
        "base_model, base_tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"unsloth/Llama-3-8B\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    dtype=dtype,\n",
        "    load_in_4bit=load_in_4bit,\n",
        ")\n",
        "\n",
        "# Set chat template for base model\n",
        "if base_tokenizer.chat_template is None:\n",
        "    base_tokenizer.chat_template = \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\"\n",
        "\n",
        "# Enable inference mode\n",
        "FastLanguageModel.for_inference(base_model)\n",
        "\n",
        "print(\"Base model loaded successfully!\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "LOADING BASE MODEL FOR COMPARISON\n",
            "================================================================================\n",
            "==((====))==  Unsloth 2026.1.4: Fast Llama patching. Transformers: 4.56.2.\n",
            "   \\\\   /|    NVIDIA A100 80GB PCIe. Num GPUs = 1. Max memory: 79.252 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.10.0+cu128. CUDA: 8.0. CUDA Toolkit: 12.8. Triton: 3.6.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.34. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Base model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PREPARING FINE-TUNED MODEL FOR INFERENCE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# The model variable already contains our fine-tuned model\n",
        "# Just enable inference mode\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "print(\"Fine-tuned model ready for inference!\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PREPARING FINE-TUNED MODEL FOR INFERENCE\n",
            "================================================================================\n",
            "Fine-tuned model ready for inference!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def generate_spotlight(model, tokenizer, prompt_text, max_new_tokens=256):\n",
        "    \"\"\"Generate spotlight given the formatted prompt\"\"\"\n",
        "    \n",
        "    # Tokenize the prompt\n",
        "    inputs = tokenizer(\n",
        "        prompt_text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=1024,\n",
        "    ).to(model.device)\n",
        "    \n",
        "    # Generate\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "    \n",
        "    # Decode only the generated part (skip the prompt)\n",
        "    generated_text = tokenizer.decode(\n",
        "        outputs[0][inputs['input_ids'].shape[1]:], \n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "    \n",
        "    return generated_text.strip()\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RUNNING INFERENCE ON TEST SET\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "num_samples = len(test_dataset)\n",
        "print(f\"\\nEvaluating on {num_samples} samples from test set...\")\n",
        "\n",
        "base_predictions = []\n",
        "ft_predictions = []\n",
        "references = []\n",
        "\n",
        "for i in tqdm(range(num_samples), desc=\"Generating predictions\"):\n",
        "    example = test_dataset[i]\n",
        "    \n",
        "    # Get the prompt and reference\n",
        "    prompt_text = example[\"prompt\"]\n",
        "    ref_text = example[\"chosen\"]\n",
        "    \n",
        "    # Generate with base model\n",
        "    base_pred = generate_spotlight(base_model, base_tokenizer, prompt_text)\n",
        "    \n",
        "    # Generate with fine-tuned model\n",
        "    ft_pred = generate_spotlight(model, tokenizer, prompt_text)\n",
        "    \n",
        "    # Store results\n",
        "    references.append(ref_text)\n",
        "    base_predictions.append(base_pred)\n",
        "    ft_predictions.append(ft_pred)\n",
        "\n",
        "print(f\"\\nGenerated {len(base_predictions)} predictions for each model!\")\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "RUNNING INFERENCE ON TEST SET\n",
            "================================================================================\n",
            "\n",
            "Evaluating on 47 samples from test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating predictions:   0%|                                                           | 0/47 [00:00<?, ?it/s]\rGenerating predictions:   2%|\u2588                                                  | 1/47 [00:18<13:54, 18.14s/it]\rGenerating predictions:   4%|\u2588\u2588\u258f                                                | 2/47 [00:35<13:05, 17.46s/it]\rGenerating predictions:   6%|\u2588\u2588\u2588\u258e                                               | 3/47 [00:52<12:38, 17.25s/it]\rGenerating predictions:   9%|\u2588\u2588\u2588\u2588\u258e                                              | 4/47 [01:09<12:23, 17.28s/it]\rGenerating predictions:  11%|\u2588\u2588\u2588\u2588\u2588\u258d                                             | 5/47 [01:26<12:01, 17.18s/it]\rGenerating predictions:  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                            | 6/47 [01:43<11:42, 17.14s/it]\rGenerating predictions:  15%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                           | 7/47 [01:55<10:18, 15.47s/it]\rGenerating predictions:  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                          | 8/47 [02:12<10:27, 16.10s/it]\rGenerating predictions:  19%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                         | 9/47 [02:29<10:22, 16.38s/it]\rGenerating predictions:  21%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                       | 10/47 [02:46<10:12, 16.55s/it]\rGenerating predictions:  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                      | 11/47 [03:03<10:01, 16.71s/it]\rGenerating predictions:  26%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                     | 12/47 [03:20<09:45, 16.72s/it]\rGenerating predictions:  28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                    | 13/47 [03:38<09:37, 17.00s/it]\rGenerating predictions:  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                   | 14/47 [03:53<09:01, 16.40s/it]\rGenerating predictions:  32%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                  | 15/47 [04:08<08:31, 16.00s/it]\rGenerating predictions:  34%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                 | 16/47 [04:25<08:25, 16.30s/it]\rGenerating predictions:  36%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                | 17/47 [04:42<08:15, 16.51s/it]\rGenerating predictions:  38%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                              | 18/47 [04:59<08:03, 16.66s/it]\rGenerating predictions:  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                             | 19/47 [05:15<07:38, 16.36s/it]\rGenerating predictions:  43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                            | 20/47 [05:25<06:37, 14.70s/it]\rGenerating predictions:  45%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                           | 21/47 [05:42<06:40, 15.39s/it]\rGenerating predictions:  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                          | 22/47 [06:00<06:38, 15.94s/it]\rGenerating predictions:  49%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                         | 23/47 [06:17<06:33, 16.39s/it]\rGenerating predictions:  51%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                        | 24/47 [06:34<06:21, 16.58s/it]\rGenerating predictions:  53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                       | 25/47 [06:51<06:08, 16.76s/it]\rGenerating predictions:  55%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                      | 26/47 [07:09<05:54, 16.89s/it]\rGenerating predictions:  57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                     | 27/47 [07:26<05:41, 17.07s/it]\rGenerating predictions:  60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                    | 28/47 [07:43<05:25, 17.14s/it]\rGenerating predictions:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                   | 29/47 [08:01<05:11, 17.33s/it]\rGenerating predictions:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                  | 30/47 [08:18<04:53, 17.24s/it]\rGenerating predictions:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                 | 31/47 [08:35<04:35, 17.22s/it]\rGenerating predictions:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                | 32/47 [08:52<04:17, 17.17s/it]\rGenerating predictions:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588               | 33/47 [09:09<04:00, 17.16s/it]\rGenerating predictions:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f             | 34/47 [09:26<03:42, 17.10s/it]\rGenerating predictions:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f            | 35/47 [09:43<03:24, 17.08s/it]\rGenerating predictions:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e           | 36/47 [10:01<03:07, 17.07s/it]\rGenerating predictions:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e          | 37/47 [10:11<02:31, 15.12s/it]\rGenerating predictions:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d         | 38/47 [10:29<02:22, 15.84s/it]\rGenerating predictions:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d        | 39/47 [10:46<02:10, 16.34s/it]\rGenerating predictions:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c       | 40/47 [11:03<01:56, 16.60s/it]\rGenerating predictions:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c      | 41/47 [11:20<01:40, 16.71s/it]\rGenerating predictions:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b     | 42/47 [11:33<01:17, 15.44s/it]\rGenerating predictions:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b    | 43/47 [11:50<01:03, 15.97s/it]\rGenerating predictions:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 44/47 [12:07<00:48, 16.25s/it]\rGenerating predictions:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 45/47 [12:24<00:33, 16.52s/it]\rGenerating predictions:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 46/47 [12:41<00:16, 16.77s/it]\rGenerating predictions: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 47/47 [12:58<00:00, 16.85s/it]\rGenerating predictions: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 47/47 [12:58<00:00, 16.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated 47 predictions for each model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CALCULATING ROUGE SCORES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "def calculate_rouge_scores(predictions, references):\n",
        "    \"\"\"Calculate average ROUGE scores\"\"\"\n",
        "    rouge1_scores = []\n",
        "    rouge2_scores = []\n",
        "    rougeL_scores = []\n",
        "    \n",
        "    for pred, ref in zip(predictions, references):\n",
        "        scores = scorer.score(ref, pred)\n",
        "        rouge1_scores.append(scores['rouge1'].fmeasure)\n",
        "        rouge2_scores.append(scores['rouge2'].fmeasure)\n",
        "        rougeL_scores.append(scores['rougeL'].fmeasure)\n",
        "    \n",
        "    return {\n",
        "        'rouge1': sum(rouge1_scores) / len(rouge1_scores),\n",
        "        'rouge2': sum(rouge2_scores) / len(rouge2_scores),\n",
        "        'rougeL': sum(rougeL_scores) / len(rougeL_scores),\n",
        "    }\n",
        "\n",
        "base_rouge = calculate_rouge_scores(base_predictions, references)\n",
        "ft_rouge = calculate_rouge_scores(ft_predictions, references)\n",
        "\n",
        "print(\"\\n\ud83d\udcca ROUGE SCORES:\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Metric':<15} {'Base Model':<15} {'Fine-tuned':<15} {'Improvement':<15}\")\n",
        "print(\"-\" * 60)\n",
        "for metric in ['rouge1', 'rouge2', 'rougeL']:\n",
        "    base_score = base_rouge[metric]\n",
        "    ft_score = ft_rouge[metric]\n",
        "    improvement = ((ft_score - base_score) / base_score) * 100\n",
        "    print(f\"{metric:<15} {base_score:<15.4f} {ft_score:<15.4f} {improvement:+.2f}%\")\n",
        "print(\"-\" * 60)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "CALCULATING ROUGE SCORES\n",
            "================================================================================\n",
            "\n",
            "\ud83d\udcca ROUGE SCORES:\n",
            "------------------------------------------------------------\n",
            "Metric          Base Model      Fine-tuned      Improvement    \n",
            "------------------------------------------------------------\n",
            "rouge1          0.1142          0.1167          +2.20%\n",
            "rouge2          0.0300          0.0285          -4.85%\n",
            "rougeL          0.0828          0.0844          +1.95%\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CALCULATING BERTSCORE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "from bert_score import score as bert_score\n",
        "\n",
        "print(\"\\nCalculating BERTScore for base model...\")\n",
        "P_base, R_base, F1_base = bert_score(\n",
        "    base_predictions,\n",
        "    references,\n",
        "    lang=\"en\",\n",
        "    verbose=False,\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "print(\"Calculating BERTScore for fine-tuned model...\")\n",
        "P_ft, R_ft, F1_ft = bert_score(\n",
        "    ft_predictions,\n",
        "    references,\n",
        "    lang=\"en\",\n",
        "    verbose=False,\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "base_bertscore = {\n",
        "    'precision': P_base.mean().item(),\n",
        "    'recall': R_base.mean().item(),\n",
        "    'f1': F1_base.mean().item(),\n",
        "}\n",
        "\n",
        "ft_bertscore = {\n",
        "    'precision': P_ft.mean().item(),\n",
        "    'recall': R_ft.mean().item(),\n",
        "    'f1': F1_ft.mean().item(),\n",
        "}\n",
        "\n",
        "print(\"\\n\ud83d\udcca BERTSCORE:\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Metric':<15} {'Base Model':<15} {'Fine-tuned':<15} {'Improvement':<15}\")\n",
        "print(\"-\" * 60)\n",
        "for metric in ['precision', 'recall', 'f1']:\n",
        "    base_score = base_bertscore[metric]\n",
        "    ft_score = ft_bertscore[metric]\n",
        "    improvement = ((ft_score - base_score) / base_score) * 100\n",
        "    print(f\"{metric:<15} {base_score:<15.4f} {ft_score:<15.4f} {improvement:+.2f}%\")\n",
        "print(\"-\" * 60)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "CALCULATING BERTSCORE\n",
            "================================================================================\n",
            "\n",
            "Calculating BERTScore for base model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5425d47c89b64f6f8255ca70eb10a53d",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "247114f672794c2b9ae5a63e17add9ab",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9d517cc28e44ad0a9b3faead110f81f",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "366cd56a45d148629e50f560736efae8",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57a3b459b1a04cc6a81f49fb3a5dc6d0",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bade3609a9954b029f94b04e8f20d279",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating BERTScore for fine-tuned model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\ud83d\udcca BERTSCORE:\n",
            "------------------------------------------------------------\n",
            "Metric          Base Model      Fine-tuned      Improvement    \n",
            "------------------------------------------------------------\n",
            "precision       0.7879          0.7910          +0.39%\n",
            "recall          0.7759          0.7757          -0.03%\n",
            "f1              0.7816          0.7830          +0.18%\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create results dataframe\n",
        "results_df = pd.DataFrame({\n",
        "    'reference': references,\n",
        "    'base_prediction': base_predictions,\n",
        "    'ft_prediction': ft_predictions,\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "results_df.to_csv('evaluation_results.csv', index=False)\n",
        "print(\"\\n Results saved to 'evaluation_results.csv'\")\n",
        "\n",
        "# Create summary\n",
        "summary_data = {\n",
        "    'Metric': ['ROUGE-1', 'ROUGE-2', 'ROUGE-L', 'BERTScore-P', 'BERTScore-R', 'BERTScore-F1'],\n",
        "    'Base Model': [\n",
        "        base_rouge['rouge1'],\n",
        "        base_rouge['rouge2'],\n",
        "        base_rouge['rougeL'],\n",
        "        base_bertscore['precision'],\n",
        "        base_bertscore['recall'],\n",
        "        base_bertscore['f1'],\n",
        "    ],\n",
        "    'Fine-tuned Model': [\n",
        "        ft_rouge['rouge1'],\n",
        "        ft_rouge['rouge2'],\n",
        "        ft_rouge['rougeL'],\n",
        "        ft_bertscore['precision'],\n",
        "        ft_bertscore['recall'],\n",
        "        ft_bertscore['f1'],\n",
        "    ],\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "summary_df['Improvement (%)'] = ((summary_df['Fine-tuned Model'] - summary_df['Base Model']) / summary_df['Base Model'] * 100).round(2)\n",
        "\n",
        "print(\"\\n\ud83d\udcca EVALUATION SUMMARY:\")\n",
        "print(summary_df.to_string(index=False))\n",
        "\n",
        "summary_df.to_csv('evaluation_summary.csv', index=False)\n",
        "print(\"\\n\u2705 Summary saved to 'evaluation_summary.csv'\")\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Results saved to 'evaluation_results.csv'\n",
            "\n",
            "\ud83d\udcca EVALUATION SUMMARY:\n",
            "      Metric  Base Model  Fine-tuned Model  Improvement (%)\n",
            "     ROUGE-1    0.114179          0.116696             2.20\n",
            "     ROUGE-2    0.029973          0.028521            -4.85\n",
            "     ROUGE-L    0.082760          0.084376             1.95\n",
            " BERTScore-P    0.787899          0.790958             0.39\n",
            " BERTScore-R    0.775877          0.775679            -0.03\n",
            "BERTScore-F1    0.781605          0.783043             0.18\n",
            "\n",
            "\u2705 Summary saved to 'evaluation_summary.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SAVING FINE-TUNED MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Save the fine-tuned model in 16-bit format\n",
        "model.save_pretrained(\"llama3_spotlight_dpo_lora\")\n",
        "tokenizer.save_pretrained(\"llama3_spotlight_dpo_lora\")\n",
        "\n",
        "print(\"\u2705 Model saved to 'llama3_spotlight_dpo_lora' directory\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "SAVING FINE-TUNED MODEL\n",
            "================================================================================\n",
            "\u2705 Model saved to 'llama3_spotlight_dpo_lora' directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "# Push LoRA adapters (lightweight, recommended)\n",
        "model.push_to_hub(\n",
        "    \"Abhishekkk3/llama3-spotlight-dpo-lora_SCITLD_test2\",  # Change to your username\n",
        "    token=\"\",  # Or leave blank if already logged in\n",
        ")\n",
        "\n",
        "tokenizer.push_to_hub(\n",
        "    \"Abhishekkk3/llama3-spotlight-dpo_lora_SCITLD_test2\",\n",
        "    token=\"\",\n",
        ")\n",
        "\n",
        "print(\"\u2705 LoRA adapters pushed to Hugging Face Hub!\")\n",
        "print(\"\ud83d\udce6 Model: YOUR_USERNAME/llama3-spotlight-dpo-lora_test2\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}